{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **04** Modeling / Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.vector_ar.vecm import VAR\n",
    "# from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Routes: 404\n"
     ]
    }
   ],
   "source": [
    "# This is a list of all of our routes\n",
    "routes = pd.read_csv('./data/model/rtm_train_updated.csv')['route'].unique()\n",
    "print(f'Total Unique Routes: {len(routes)}')\n",
    "# routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a placeholder for the routes -- we plan to make 375 different models\n",
    "itinerary = 'Albany, NY - Chicago, IL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read In Data\n",
    "def df_read(df_file_path, route):\n",
    "    \n",
    "    # Import Dataframe \n",
    "    df = pd.read_csv(df_file_path)[pd.read_csv(df_file_path)['route'] == route].dropna(axis=1)\n",
    "    df.index = pd.to_datetime(df['year-month'])\n",
    "    df = df.drop(columns=['year-month'])\n",
    "#     print(df.shape)\n",
    "    \n",
    "    # Extract Potential Features\n",
    "    features = sorted(df.drop(columns=['airfare', 'route', 'pop_origin', 'pop_dest', 'origin_lat', 'origin_long', 'dest_lat', 'dest_long']).columns)\n",
    "    \n",
    "    remove_options = [i.replace('sf_', \"\").replace('_diff_1', \"\").replace('_diff_2', \"\") for i in features if \"sf_\" in i]\n",
    "    \n",
    "    features = sorted(set(features) - set(remove_options))\n",
    "    \n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary to store train & unseen dataframes as well a their potential features\n",
    "- **THIS WILL TAKE 20 MINUTES TO RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albany, NY - Chicago, IL\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['route', 'train_dataframe', 'test_dataframe', 'potential_features'])"
      ]
     },
     "execution_count": 1537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 MIN TO RUN!!!\n",
    "# Create a dictionary storing all of our route train data, route unseen data, and potential features\n",
    "\n",
    "all_route_dict = {}\n",
    "for rte in routes: # only looking at 10 routes right now\n",
    "    route_dict = {}\n",
    "    route_dict['route'] = rte\n",
    "    route_dict['train_dataframe'] = df_read('./data/model/rtm_train_updated.csv', route=rte)[0]\n",
    "    route_dict['test_dataframe'] = df_read('./data/model/rtm_test_updated.csv', route=rte)[0]\n",
    "    route_dict['potential_features'] = df_read('./data/model/rtm_train_updated.csv', route=rte)[1]\n",
    "    all_route_dict[rte] = route_dict\n",
    "\n",
    "# Taking a look at the dictionary -- looking at the keys of a specific route here\n",
    "print(itinerary)\n",
    "print()\n",
    "all_route_dict[itinerary].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling / Visualization / Analysis Function\n",
    "- The function below takes in the training dataset & the unseen dataset as well as routes\n",
    "- It will visualize the results of our model for the test dataset as well as predictions on unseen data\n",
    "- Additionally it will show us R2, RMSE, and MSE data to compare model/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimize_function(itinerary_route='Tampa, FL - Washington, DC', target_variable='airfare', pv_thresh=0.05):\n",
    "    \n",
    "    df = all_route_dict[itinerary_route]['train_dataframe']\n",
    "    unseen_df = all_route_dict[itinerary_route]['test_dataframe']\n",
    "    features_list = all_route_dict[itinerary_route]['potential_features']\n",
    "    \n",
    "    X = df[features_list]\n",
    "    y = df[target_variable]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=False)\n",
    "    X_train = sm.add_constant(X_train, has_constant='add')          \n",
    "    X_test = sm.add_constant(X_test, has_constant='add')        \n",
    "    X_train.dropna(inplace=True)                                     # dropping NA values to ensure model computes\n",
    "    y_train = y_train[X_train.index]                                 # Subset y to match the index from X\n",
    "    linear_model = sm.OLS(y_train, X_train).fit()\n",
    "    \n",
    "    X_unseen = unseen_df[features_list]                          # Create X variable with matching features from Traing Data\n",
    "    X_unseen = sm.add_constant(X_unseen, has_constant='add')         # Add X Constant\n",
    "    unseen_pred = linear_model.predict(X_unseen)                     # Make Predictions -- for 'airfare'\n",
    "    unseen_df['airfare_predictions'] = unseen_pred   # save predictions to unseen route df\n",
    "    unseen_df = unseen_df.dropna() \n",
    "    \n",
    "    count = 1\n",
    "    # Plot Train/Test & Model Predictions on Training Dataset\n",
    "    plt.figure(figsize=(12, 4))                                                                # Set figure size\n",
    "    plt.plot(y_train.index, y_train.values, color = 'blue', label='Training Values')           # Plot training data\n",
    "    plt.plot(y_test.index, y_test.values, color = 'orange', label='Test Values', linewidth=10) # Plot testing data\n",
    "    plt.plot(linear_model.predict(X_test), color = 'green', label='Predicted Test Values')                     # Plot predicted test values\n",
    "    plt.title(label = 'Train / Test + Predictions - Model_' + str(count) + ': ' + str(itinerary_route), fontsize=20)            # Plot Title\n",
    "    plt.ylabel('Airfare Ticket Price ($ USD)', size=12)                                        # Y Label\n",
    "    plt.xlabel('Year-Month', size=12)                                                          # X label\n",
    "    plt.grid()                                                                                 # add grid\n",
    "    plt.xticks(fontsize=12)                                                                    # Resize X-Ticks\n",
    "    plt.yticks(fontsize=12)                                                                    # Resize Y-Ticks\n",
    "    plt.legend()                                                                               # Legend\n",
    "    plt.savefig('./visualizations/' + itinerary_route + '_train_' + str(count) + '.png', transparent=True, bbox_inches = \"tight\")\n",
    "    plt.close();    \n",
    "    \n",
    "    # Plot Predictions on our unseen dataframe\n",
    "    plt.figure(figsize=(12, 4)) # Set figure size\n",
    "    plt.plot(unseen_df[target_variable], color = 'orange', label='Actual Airfare Price', linewidth=10)    # Plot actual data.\n",
    "    plt.plot(unseen_df['airfare_predictions'], color = 'green', label='Predicted Airfare Price')    # Plot predicted unseen values\n",
    "    plt.title(label = 'Predictions (unseen data) - Model_' + str(count) + ': ' + str(itinerary_route), fontsize=20) # add title\n",
    "    plt.ylabel('Airfare Ticket Price ($ USD)', size=12)\n",
    "    plt.xlabel('Year-Month', size=12)\n",
    "    plt.grid()\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.savefig('./visualizations/' + itinerary_route + '_unseen_' + str(count) + '.png', transparent=True, bbox_inches = \"tight\")\n",
    "    plt.close();    \n",
    "    \n",
    "    \n",
    "    ###################\n",
    "    model_dict = {}\n",
    "    scoring_dict = {}\n",
    "    score_dict = {}\n",
    "    model_dict['lin_model_' + str(count)] = linear_model\n",
    "    \n",
    "    # ANALYTICS\n",
    "#     score_dict['y_train_pred'] = linear_model.predict(X_train) # Generate Predictions\n",
    "#     score_dict['y_test_pred'] = linear_model.predict(X_test) # Generate Predictions\n",
    "#     score_dict['y_test_baseline'] = [y_test.mean()] * len(y_test)  # Baseline\n",
    "    score_dict['train_r2'] = r2_score(y_train, linear_model.predict(X_train))  # Scoring\n",
    "    score_dict['train_rmse'] = mean_squared_error(y_train, linear_model.predict(X_train), squared=False) # Scoring\n",
    "    score_dict['test_r2'] = r2_score(y_test, linear_model.predict(X_test)) # Scoring\n",
    "    score_dict['test_rmse'] = mean_squared_error(y_test, linear_model.predict(X_test), squared=False) # Scoring\n",
    "    score_dict['base_r2'] = r2_score(y_test, [y_test.mean()] * len(y_test)) # Scoring\n",
    "    score_dict['base_rmse'] = mean_squared_error(y_test, [y_test.mean()] * len(y_test), squared=False) # Scoring\n",
    "    score_dict['unseen_r2'] = r2_score(unseen_df[target_variable], unseen_df.airfare_predictions) # Scoring\n",
    "    score_dict['unseen_rmse'] = mean_squared_error(unseen_df[target_variable], unseen_df.airfare_predictions, squared=False) # Scoring\n",
    "    \n",
    "    scoring_dict['analytics_' + str(count)] = score_dict\n",
    "#     score_dict['analytics_' + str(count)] = score_dict\n",
    "    ###################\n",
    "    \n",
    "    model_dict = {}\n",
    "    scoring_dict = {}\n",
    "    score_dict = {}\n",
    "\n",
    "    removed_features_list = []\n",
    "    condition = linear_model.pvalues[linear_model.pvalues.index != 'const'].sort_values(ascending=False).max()\n",
    "    \n",
    "    while condition > pv_thresh:\n",
    "        count +=1\n",
    "        removed_features_list.append(linear_model.pvalues[linear_model.pvalues.index != 'const'].sort_values(ascending=False).index[0])\n",
    "#         print(f'Removed: {linear_model.pvalues.sort_values(ascending=False).index[0]}')\n",
    "        features_list = list(set(features_list) - set(removed_features_list))\n",
    "        \n",
    "        X = df[features_list]\n",
    "        y = df['airfare']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=False)\n",
    "        X_train = sm.add_constant(X_train, has_constant='add')          \n",
    "        X_test = sm.add_constant(X_test, has_constant='add')        \n",
    "        X_train.dropna(inplace=True)                                     # dropping NA values to ensure model computes\n",
    "        y_train = y_train[X_train.index]                                 # Subset y to match the index from X\n",
    "        linear_model = sm.OLS(y_train, X_train).fit()\n",
    "        \n",
    "        condition = linear_model.pvalues.sort_values(ascending=False).max()\n",
    "        \n",
    "        X_unseen = unseen_df[features_list]                          # Create X variable with matching features from Traing Data\n",
    "        X_unseen = sm.add_constant(X_unseen, has_constant='add')         # Add X Constant\n",
    "        unseen_pred = linear_model.predict(X_unseen)                     # Make Predictions -- for 'airfare'\n",
    "        unseen_df['airfare_predictions'] = unseen_pred   # save predictions to unseen route df\n",
    "        unseen_df = unseen_df.dropna() \n",
    "        \n",
    "        score_dict = {}\n",
    "        # ANALYTICS\n",
    "#         score_dict['y_train_pred'] = linear_model.predict(X_train) # Generate Predictions\n",
    "#         score_dict['y_test_pred'] = linear_model.predict(X_test) # Generate Predictions\n",
    "#         score_dict['y_test_baseline'] = [y_test.mean()] * len(y_test)  # Baseline\n",
    "        score_dict['train_r2'] = r2_score(y_train, linear_model.predict(X_train))  # Scoring\n",
    "        score_dict['train_rmse'] = mean_squared_error(y_train, linear_model.predict(X_train), squared=False) # Scoring\n",
    "        score_dict['test_r2'] = r2_score(y_test, linear_model.predict(X_test)) # Scoring\n",
    "        score_dict['test_rmse'] = mean_squared_error(y_test, linear_model.predict(X_test), squared=False) # Scoring\n",
    "        score_dict['base_r2'] = r2_score(y_test, [y_test.mean()] * len(y_test)) # Scoring\n",
    "        score_dict['base_rmse'] = mean_squared_error(y_test, [y_test.mean()] * len(y_test), squared=False) # Scoring\n",
    "        score_dict['unseen_r2'] = r2_score(unseen_df[target_variable], unseen_df.airfare_predictions) # Scoring\n",
    "        score_dict['unseen_rmse'] = mean_squared_error(unseen_df[target_variable], unseen_df.airfare_predictions, squared=False) # Scoring\n",
    "        scoring_dict['analytics_' + str(count)] = score_dict\n",
    "        ###################\n",
    " \n",
    "        model_dict['lin_model_' + str(count)] = linear_model\n",
    "    \n",
    "    all_route_dict[itinerary_route]['models'] = model_dict\n",
    "    all_route_dict[itinerary_route]['analytics'] = scoring_dict\n",
    "    all_route_dict[itinerary_route]['final_features'] = features_list\n",
    "    all_route_dict[itinerary_route]['final_model'] = linear_model\n",
    "    \n",
    "    # Plot Train/Test & Model Predictions on Training Dataset\n",
    "    plt.figure(figsize=(12, 4))                                                                # Set figure size\n",
    "    plt.plot(y_train.index, y_train.values, color = 'blue', label='Training Values')           # Plot training data\n",
    "    plt.plot(y_test.index, y_test.values, color = 'orange', label='Test Values', linewidth=10) # Plot testing data\n",
    "    plt.plot(linear_model.predict(X_test), color = 'green', label='Predicted Test Values')                     # Plot predicted test values\n",
    "    plt.title(label = 'Train / Test + Predictions - Model_' + str(count) + ': ' + str(itinerary_route), fontsize=20)            # Plot Title\n",
    "    plt.ylabel('Airfare Ticket Price ($ USD)', size=12)                                        # Y Label\n",
    "    plt.xlabel('Year-Month', size=12)                                                          # X label\n",
    "    plt.grid()                                                                                 # add grid\n",
    "    plt.xticks(fontsize=12)                                                                    # Resize X-Ticks\n",
    "    plt.yticks(fontsize=12)                                                                    # Resize Y-Ticks\n",
    "    plt.legend()                                                                               # Legend\n",
    "    plt.savefig('./visualizations/' + itinerary_route + '_train_' + str(count) + '.png', transparent=True, bbox_inches = \"tight\")\n",
    "    plt.close();    \n",
    "    \n",
    "    # Plot Predictions on our unseen dataframe\n",
    "    plt.figure(figsize=(12, 4)) # Set figure size\n",
    "    plt.plot(unseen_df[target_variable], color = 'orange', label='Actual Airfare Price', linewidth=10)    # Plot actual data.\n",
    "    plt.plot(unseen_df['airfare_predictions'], color = 'red', label='Predicted Airfare Price')    # Plot predicted unseen values\n",
    "    plt.title(label = 'Predictions (unseen data) - Model_' + str(count) + ': ' + str(itinerary_route), fontsize=20) # add title\n",
    "    plt.ylabel('Airfare Ticket Price ($ USD)', size=12)\n",
    "    plt.xlabel('Year-Month', size=12)\n",
    "    plt.grid()\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.savefig('./visualizations/' + itinerary_route + '_unseen_final_' + str(count) + '.png', transparent=True, bbox_inches = \"tight\")\n",
    "    plt.close();                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's apply our function to all of our data\n",
    "- Let's leverage our functions and run them through a loop of all our our routes\n",
    "- Each route will have its own custom fit model to make predictions\n",
    "- Output will be visualizations and scores\n",
    "- Next Steps:\n",
    "    - Analyze stats and tune function to output best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rte in list(all_route_dict.keys()):\n",
    "    model_optimize_function(itinerary_route=rte)\n",
    "    plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Create a Dataframe with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8474, 10)\n",
      "(8474, 1)\n",
      "(8474, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_order</th>\n",
       "      <th>linear_model</th>\n",
       "      <th>route</th>\n",
       "      <th>base_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>unseen_r2</th>\n",
       "      <th>base_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>unseen_rmse</th>\n",
       "      <th>train_r2_overfit</th>\n",
       "      <th>train_rmse_overfit</th>\n",
       "      <th>unseen_r2_overfit</th>\n",
       "      <th>unseen_rmse_overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765730</td>\n",
       "      <td>-11.211441</td>\n",
       "      <td>-97.827997</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.095879</td>\n",
       "      <td>51.277072</td>\n",
       "      <td>99.984673</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765729</td>\n",
       "      <td>-11.236172</td>\n",
       "      <td>-98.036607</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.095937</td>\n",
       "      <td>51.328969</td>\n",
       "      <td>100.090144</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765719</td>\n",
       "      <td>-11.321700</td>\n",
       "      <td>-98.923642</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.096368</td>\n",
       "      <td>51.508045</td>\n",
       "      <td>100.537380</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765704</td>\n",
       "      <td>-11.312178</td>\n",
       "      <td>-96.060562</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.097065</td>\n",
       "      <td>51.488139</td>\n",
       "      <td>99.086580</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765672</td>\n",
       "      <td>-11.532504</td>\n",
       "      <td>-97.750906</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.098491</td>\n",
       "      <td>51.946786</td>\n",
       "      <td>99.945669</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_order                                       linear_model  \\\n",
       "0            2  <statsmodels.regression.linear_model.Regressio...   \n",
       "1            3  <statsmodels.regression.linear_model.Regressio...   \n",
       "2            4  <statsmodels.regression.linear_model.Regressio...   \n",
       "3            5  <statsmodels.regression.linear_model.Regressio...   \n",
       "4            6  <statsmodels.regression.linear_model.Regressio...   \n",
       "\n",
       "                      route       base_r2  train_r2    test_r2  unseen_r2  \\\n",
       "0  Albany, NY - Chicago, IL -2.220446e-16  0.765730 -11.211441 -97.827997   \n",
       "1  Albany, NY - Chicago, IL -2.220446e-16  0.765729 -11.236172 -98.036607   \n",
       "2  Albany, NY - Chicago, IL -2.220446e-16  0.765719 -11.321700 -98.923642   \n",
       "3  Albany, NY - Chicago, IL -2.220446e-16  0.765704 -11.312178 -96.060562   \n",
       "4  Albany, NY - Chicago, IL -2.220446e-16  0.765672 -11.532504 -97.750906   \n",
       "\n",
       "   base_rmse  train_rmse  test_rmse  unseen_rmse  train_r2_overfit  \\\n",
       "0  14.673704   21.095879  51.277072    99.984673              True   \n",
       "1  14.673704   21.095937  51.328969   100.090144              True   \n",
       "2  14.673704   21.096368  51.508045   100.537380              True   \n",
       "3  14.673704   21.097065  51.488139    99.086580              True   \n",
       "4  14.673704   21.098491  51.946786    99.945669              True   \n",
       "\n",
       "   train_rmse_overfit  unseen_r2_overfit  unseen_rmse_overfit  \n",
       "0                True              False                False  \n",
       "1                True              False                False  \n",
       "2                True              False                False  \n",
       "3                True              False                False  \n",
       "4                True              False                False  "
      ]
     },
     "execution_count": 1540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's create a dataframe with all of our results\n",
    "\n",
    "answers_df = pd.DataFrame()\n",
    "for i in list(all_route_dict.keys()):\n",
    "    rte_df = pd.DataFrame()\n",
    "    for j in list(all_route_dict[i]['analytics'].keys()):\n",
    "        new_dataframe = pd.DataFrame(all_route_dict[i]['analytics'][j], index=[0])\n",
    "        new_dataframe['analytics_count'] = j\n",
    "        new_dataframe['route'] = i\n",
    "        rte_df = pd.concat([rte_df, new_dataframe])\n",
    "    answers_df = pd.concat([answers_df, rte_df])\n",
    "   \n",
    "other_df = pd.DataFrame()\n",
    "for i in list(all_route_dict.keys()):\n",
    "    newly_df = pd.DataFrame.from_dict(all_route_dict[i]['models'], orient='index')\n",
    "    other_df = pd.concat([other_df, newly_df])\n",
    "\n",
    "print(answers_df.shape)\n",
    "print(other_df.shape)\n",
    "\n",
    "answers_df.reset_index(inplace=True)\n",
    "other_df.reset_index(inplace=True)\n",
    "\n",
    "# Merge the two DF's above\n",
    "scoring_df = pd.merge(other_df, answers_df, left_index=True, right_index=True)\n",
    "scoring_df = scoring_df[['index_x', 0, 'route', 'base_r2', 'train_r2', 'test_r2', 'unseen_r2', 'base_rmse', 'train_rmse', 'test_rmse','unseen_rmse']].rename(columns={0 : 'linear_model', 'index_x' : 'model_order'})\n",
    "\n",
    "# Scoring Analytics --------------------------\n",
    "\n",
    "#Change Model Order column to integer\n",
    "scoring_df['model_order'] = scoring_df['model_order'].apply(lambda x: int(x.replace('lin_model_', \"\")))\n",
    "\n",
    "# Train VS Test\n",
    "scoring_df['train_r2_overfit'] = scoring_df['train_r2'] > scoring_df['test_r2']\n",
    "scoring_df['train_rmse_overfit'] = scoring_df['train_rmse'] < scoring_df['test_rmse']\n",
    "\n",
    "# Unseen VS Model Predictions\n",
    "scoring_df['unseen_r2_overfit'] = scoring_df['unseen_r2'] > scoring_df['test_r2']\n",
    "scoring_df['unseen_rmse_overfit'] = scoring_df['unseen_rmse'] < scoring_df['test_rmse']\n",
    "\n",
    "\n",
    "print(scoring_df.shape)\n",
    "scoring_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    283\n",
       "True     121\n",
       "Name: greater, dtype: int64"
      ]
     },
     "execution_count": 1541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 265 out of 375 testing scores outperformed\n",
    "realquick = scoring_df.groupby('route')[['base_r2', 'train_r2', 'test_r2']].max()\n",
    "realquick['greater'] = realquick['test_r2'] > realquick['base_r2']\n",
    "realquick['greater'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LET'S TAKE A LOOK AT OUR MOST POPULAR ROUTE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUTE: Dallas, TX - Houston, TX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.3356061729191988,\n",
       " 'train_rmse': 4.3807916320680835,\n",
       " 'test_r2': -13.134128246142426,\n",
       " 'test_rmse': 15.899739689129524,\n",
       " 'base_r2': 2.220446049250313e-16,\n",
       " 'base_rmse': 4.229173481111092,\n",
       " 'unseen_r2': -198.2221467339791,\n",
       " 'unseen_rmse': 36.39835549646081}"
      ]
     },
     "execution_count": 1544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_route_dict['Dallas, TX - Houston, TX']['analytics'].keys()\n",
    "all_route_dict['Dallas, TX - Houston, TX']['analytics']['analytics_2']\n",
    "all_route_dict['Dallas, TX - Houston, TX']['analytics']['analytics_21']\n",
    "\n",
    "# final analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sf_cost_per_mile_diff_1',\n",
       " 'sf_flight_revenue_diff_2',\n",
       " 'sf_airfare_diff_1',\n",
       " 'sf_time_diff_1',\n",
       " 'sf_passengers_diff_2',\n",
       " 'sf_total_flight_cost_diff_2',\n",
       " 'dist_miles']"
      ]
     },
     "execution_count": 1545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final features\n",
    "all_route_dict['Dallas, TX - Houston, TX']['final_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>airfare</td>     <th>  R-squared:         </th> <td>   0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>2.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:30:53</td>     <th>  Log-Likelihood:    </th> <td> -237.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    82</td>      <th>  AIC:               </th> <td>   489.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    75</td>      <th>  BIC:               </th> <td>   505.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>   -0.0030</td> <td>    0.001</td> <td>   -4.711</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_cost_per_mile_diff_1</th>     <td>  911.6358</td> <td>  347.708</td> <td>    2.622</td> <td> 0.011</td> <td>  218.966</td> <td> 1604.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_flight_revenue_diff_2</th>    <td> 4.358e-06</td> <td> 2.08e-06</td> <td>    2.099</td> <td> 0.039</td> <td> 2.22e-07</td> <td> 8.49e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_airfare_diff_1</th>           <td>   -4.0965</td> <td>    1.787</td> <td>   -2.293</td> <td> 0.025</td> <td>   -7.656</td> <td>   -0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_time_diff_1</th>              <td>   -1.2160</td> <td>    0.258</td> <td>   -4.711</td> <td> 0.000</td> <td>   -1.730</td> <td>   -0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_passengers_diff_2</th>        <td>   -0.0004</td> <td>    0.000</td> <td>   -2.159</td> <td> 0.034</td> <td>   -0.001</td> <td>-2.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_total_flight_cost_diff_2</th> <td> 2.335e-05</td> <td> 1.04e-05</td> <td>    2.255</td> <td> 0.027</td> <td> 2.73e-06</td> <td>  4.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_miles</th>                  <td>    2.5084</td> <td>    0.454</td> <td>    5.523</td> <td> 0.000</td> <td>    1.604</td> <td>    3.413</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.809</td> <th>  Durbin-Watson:     </th> <td>   0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.246</td> <th>  Jarque-Bera (JB):  </th> <td>   2.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.419</td> <th>  Prob(JB):          </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.050</td> <th>  Cond. No.          </th> <td>9.55e+21</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.9e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                airfare   R-squared:                       0.336\n",
       "Model:                            OLS   Adj. R-squared:                  0.282\n",
       "Method:                 Least Squares   F-statistic:                     6.314\n",
       "Date:                Mon, 12 Oct 2020   Prob (F-statistic):           2.08e-05\n",
       "Time:                        20:30:53   Log-Likelihood:                -237.49\n",
       "No. Observations:                  82   AIC:                             489.0\n",
       "Df Residuals:                      75   BIC:                             505.8\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                          -0.0030      0.001     -4.711      0.000      -0.004      -0.002\n",
       "sf_cost_per_mile_diff_1       911.6358    347.708      2.622      0.011     218.966    1604.306\n",
       "sf_flight_revenue_diff_2     4.358e-06   2.08e-06      2.099      0.039    2.22e-07    8.49e-06\n",
       "sf_airfare_diff_1              -4.0965      1.787     -2.293      0.025      -7.656      -0.537\n",
       "sf_time_diff_1                 -1.2160      0.258     -4.711      0.000      -1.730      -0.702\n",
       "sf_passengers_diff_2           -0.0004      0.000     -2.159      0.034      -0.001   -2.92e-05\n",
       "sf_total_flight_cost_diff_2  2.335e-05   1.04e-05      2.255      0.027    2.73e-06     4.4e-05\n",
       "dist_miles                      2.5084      0.454      5.523      0.000       1.604       3.413\n",
       "==============================================================================\n",
       "Omnibus:                        2.809   Durbin-Watson:                   0.181\n",
       "Prob(Omnibus):                  0.246   Jarque-Bera (JB):                2.408\n",
       "Skew:                           0.419   Prob(JB):                        0.300\n",
       "Kurtosis:                       3.050   Cond. No.                     9.55e+21\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.9e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final model\n",
    "all_route_dict['Dallas, TX - Houston, TX']['final_model'].summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Models: 22\n",
    "- Initial Features - 27\n",
    "- Ending Features - 6\n",
    "\n",
    "- Benchmarks\n",
    "    - Base R2 - 2.22^-16\n",
    "    - Base RMSE - $4.23\n",
    "- Initial Metrics (model 1)\n",
    "    - Train R2 - 87.85%\n",
    "    - Test R2 - 28.77%\n",
    "    - Train RMSE - $1.87\n",
    "    - Test RMSE - $3.57\n",
    "- Final Metrics (model 22)\n",
    "    - Train R2 - 85.62%\n",
    "    - Test R2 - 64.59%\n",
    "    - Train RMSE - $2.04\n",
    "    - Test RMSE - $2.52\n",
    "- Scores on Unseen Data\n",
    "    - Unseen R2 -  (260.82 * 100)% \n",
    "    - Unseen RMSE - $41.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Immediately we are outperfroming our Baseline Scores, but not by much given it's a low cost ticket\n",
    "- Looking at how poorly this performs against unseen data we could not move forward with this route specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/DallasTXHoustonTX_train_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='.//Keeping_Visualizations/Dallas, TX - Houston, TX_unseen_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/Dallas, TX - Houston, TX_train_22.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/Dallas, TX - Houston, TX_unseen_final_22.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOW LET'S TAKE A LOOK AT ANOTHER (MORE SUCCESSFUL) ROUTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUTE: Atlanta, GA - Austin, TX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9821004334857656,\n",
       " 'train_rmse': 2.5799529950916957,\n",
       " 'test_r2': 0.9727441351175675,\n",
       " 'test_rmse': 4.951731579481935,\n",
       " 'base_r2': 0.0,\n",
       " 'base_rmse': 29.99349747815719,\n",
       " 'unseen_r2': 0.9454592031032688,\n",
       " 'unseen_rmse': 6.640727221172836}"
      ]
     },
     "execution_count": 1547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_route_dict['Atlanta, GA - Austin, TX']['analytics'].keys()\n",
    "all_route_dict['Atlanta, GA - Austin, TX']['analytics']['analytics_2']\n",
    "all_route_dict['Atlanta, GA - Austin, TX']['analytics']['analytics_21']\n",
    "\n",
    "# final analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sf_total_flight_miles_diff_1',\n",
       " 'sf_num_of_flights_lag_12_diff_1',\n",
       " 'sf_time_diff_1',\n",
       " 'seat_capacity_lag_2',\n",
       " 'passengers',\n",
       " 'dist_miles',\n",
       " 'flight_revenue']"
      ]
     },
     "execution_count": 1548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final features\n",
    "all_route_dict['Atlanta, GA - Austin, TX']['final_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>airfare</td>     <th>  R-squared:         </th> <td>   0.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   685.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>2.23e-63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:30:53</td>     <th>  Log-Likelihood:    </th> <td> -194.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    82</td>      <th>  AIC:               </th> <td>   402.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    75</td>      <th>  BIC:               </th> <td>   419.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                           <td>   -0.0122</td> <td>    0.005</td> <td>   -2.653</td> <td> 0.010</td> <td>   -0.021</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_total_flight_miles_diff_1</th>    <td>    0.0001</td> <td> 3.66e-05</td> <td>    3.655</td> <td> 0.000</td> <td> 6.08e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_num_of_flights_lag_12_diff_1</th> <td>    0.1031</td> <td>    0.025</td> <td>    4.054</td> <td> 0.000</td> <td>    0.052</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_time_diff_1</th>                  <td>   -4.9393</td> <td>    1.862</td> <td>   -2.653</td> <td> 0.010</td> <td>   -8.648</td> <td>   -1.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>seat_capacity_lag_2</th>             <td>    0.0005</td> <td>    0.000</td> <td>    4.309</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>passengers</th>                      <td>   -0.0151</td> <td>    0.000</td> <td>  -43.684</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_miles</th>                      <td>    2.7425</td> <td>    0.927</td> <td>    2.959</td> <td> 0.004</td> <td>    0.896</td> <td>    4.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>flight_revenue</th>                  <td> 6.142e-05</td> <td> 1.14e-06</td> <td>   54.072</td> <td> 0.000</td> <td> 5.92e-05</td> <td> 6.37e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.540</td> <th>  Durbin-Watson:     </th> <td>   0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.008</td> <th>  Jarque-Bera (JB):  </th> <td>   9.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.810</td> <th>  Prob(JB):          </th> <td> 0.00872</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.390</td> <th>  Cond. No.          </th> <td>3.99e+21</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.02e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                airfare   R-squared:                       0.982\n",
       "Model:                            OLS   Adj. R-squared:                  0.981\n",
       "Method:                 Least Squares   F-statistic:                     685.8\n",
       "Date:                Mon, 12 Oct 2020   Prob (F-statistic):           2.23e-63\n",
       "Time:                        20:30:53   Log-Likelihood:                -194.07\n",
       "No. Observations:                  82   AIC:                             402.1\n",
       "Df Residuals:                      75   BIC:                             419.0\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "const                              -0.0122      0.005     -2.653      0.010      -0.021      -0.003\n",
       "sf_total_flight_miles_diff_1        0.0001   3.66e-05      3.655      0.000    6.08e-05       0.000\n",
       "sf_num_of_flights_lag_12_diff_1     0.1031      0.025      4.054      0.000       0.052       0.154\n",
       "sf_time_diff_1                     -4.9393      1.862     -2.653      0.010      -8.648      -1.231\n",
       "seat_capacity_lag_2                 0.0005      0.000      4.309      0.000       0.000       0.001\n",
       "passengers                         -0.0151      0.000    -43.684      0.000      -0.016      -0.014\n",
       "dist_miles                          2.7425      0.927      2.959      0.004       0.896       4.589\n",
       "flight_revenue                   6.142e-05   1.14e-06     54.072      0.000    5.92e-05    6.37e-05\n",
       "==============================================================================\n",
       "Omnibus:                        9.540   Durbin-Watson:                   0.997\n",
       "Prob(Omnibus):                  0.008   Jarque-Bera (JB):                9.485\n",
       "Skew:                          -0.810   Prob(JB):                      0.00872\n",
       "Kurtosis:                       3.390   Cond. No.                     3.99e+21\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.02e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final model\n",
    "all_route_dict['Atlanta, GA - Austin, TX']['final_model'].summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Models - 21\n",
    "- Initial Features - 27\n",
    "- Ending Features - 7\n",
    "\n",
    "- Benchmarks\n",
    "    - Base R2 - $0.00\n",
    "    - Base RMSE - $29.99\n",
    "- Initial Metrics (model 1)\n",
    "    - Train R2 - 98.48%\n",
    "    - Test R2 - 97.35%\n",
    "    - Train RMSE - $2.38\n",
    "    - Test RMSE - $4.89\n",
    "- Final Metrics (model 21)\n",
    "    - Train R2 - 98.21%\n",
    "    - Test R2 - 97.27%\n",
    "    - Train RMSE - $2.58\n",
    "    - Test RMSE - $4.95\n",
    "- Unseen Data\n",
    "    - Unseen R2 - 94.55%\n",
    "    - Unseen RMSE - $6.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Immediately we are outperfroming our Baseline Scores, however tuning this model leads us to see no improvement.\n",
    "- But do you really need to see improvement when you are scoring 98%.  A good time series model has minimal features they say!\n",
    "- Given the price ranges roughly from 90-105 USD, this model is deemed a success performing well on unseen data!.\n",
    "- Would highly encourage an individual to book travel that was listed below this as you would be finding a bargain!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOWEVER! Note the model performs poorly on unseen data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/Atlanta, GA - Austin, TX_train_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/Atlanta, GA - Austin, TX_unseen_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='.//Keeping_Visualizations/Atlanta, GA - Austin, TX_train_21.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./Keeping_Visualizations/Atlanta, GA - Austin, TX_unseen_final_21.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Able to reduce average RMSE by 21.85% -- Improved Score on 299 out of 375 routes\n",
    "## - Success with 89 out of 375 routes in predicting airfare prices near perfect r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>model_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albuquerque, NM - Chicago, IL</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albuquerque, NM - Dallas, TX</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albuquerque, NM - Houston, TX</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           route  model_order\n",
       "0       Albany, NY - Chicago, IL           25\n",
       "1       Albany, NY - Orlando, FL           18\n",
       "2  Albuquerque, NM - Chicago, IL           22\n",
       "3   Albuquerque, NM - Dallas, TX           26\n",
       "4  Albuquerque, NM - Houston, TX           26"
      ]
     },
     "execution_count": 1550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_score = scoring_df.groupby('route')[['model_order']].max().reset_index()\n",
    "join_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_order</th>\n",
       "      <th>linear_model</th>\n",
       "      <th>route</th>\n",
       "      <th>base_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>unseen_r2</th>\n",
       "      <th>base_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>unseen_rmse</th>\n",
       "      <th>train_r2_overfit</th>\n",
       "      <th>train_rmse_overfit</th>\n",
       "      <th>unseen_r2_overfit</th>\n",
       "      <th>unseen_rmse_overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.765730</td>\n",
       "      <td>-11.211441</td>\n",
       "      <td>-97.827997</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>21.095879</td>\n",
       "      <td>51.277072</td>\n",
       "      <td>99.984673</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.531803</td>\n",
       "      <td>-1.399643</td>\n",
       "      <td>-34.334557</td>\n",
       "      <td>10.436395</td>\n",
       "      <td>9.252736</td>\n",
       "      <td>16.166790</td>\n",
       "      <td>47.417078</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_order                                       linear_model  \\\n",
       "0             2  <statsmodels.regression.linear_model.Regressio...   \n",
       "24            2  <statsmodels.regression.linear_model.Regressio...   \n",
       "\n",
       "                       route       base_r2  train_r2    test_r2  unseen_r2  \\\n",
       "0   Albany, NY - Chicago, IL -2.220446e-16  0.765730 -11.211441 -97.827997   \n",
       "24  Albany, NY - Orlando, FL  0.000000e+00  0.531803  -1.399643 -34.334557   \n",
       "\n",
       "    base_rmse  train_rmse  test_rmse  unseen_rmse  train_r2_overfit  \\\n",
       "0   14.673704   21.095879  51.277072    99.984673              True   \n",
       "24  10.436395    9.252736  16.166790    47.417078              True   \n",
       "\n",
       "    train_rmse_overfit  unseen_r2_overfit  unseen_rmse_overfit  \n",
       "0                 True              False                False  \n",
       "24                True              False                False  "
      ]
     },
     "execution_count": 1551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dataframe of initial scores\n",
    "initial_score_df = scoring_df[scoring_df['model_order'] == 2]\n",
    "initial_score_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>model_order</th>\n",
       "      <th>linear_model</th>\n",
       "      <th>base_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>unseen_r2</th>\n",
       "      <th>base_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>unseen_rmse</th>\n",
       "      <th>train_r2_overfit</th>\n",
       "      <th>train_rmse_overfit</th>\n",
       "      <th>unseen_r2_overfit</th>\n",
       "      <th>unseen_rmse_overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.732433</td>\n",
       "      <td>-5.166856</td>\n",
       "      <td>-45.947541</td>\n",
       "      <td>14.673704</td>\n",
       "      <td>22.545295</td>\n",
       "      <td>36.439436</td>\n",
       "      <td>68.912794</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>18</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>-0.692976</td>\n",
       "      <td>-26.473834</td>\n",
       "      <td>10.436395</td>\n",
       "      <td>10.332903</td>\n",
       "      <td>13.579255</td>\n",
       "      <td>41.811389</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route  model_order  \\\n",
       "0  Albany, NY - Chicago, IL           25   \n",
       "1  Albany, NY - Orlando, FL           18   \n",
       "\n",
       "                                        linear_model       base_r2  train_r2  \\\n",
       "0  <statsmodels.regression.linear_model.Regressio... -2.220446e-16  0.732433   \n",
       "1  <statsmodels.regression.linear_model.Regressio...  0.000000e+00  0.416107   \n",
       "\n",
       "    test_r2  unseen_r2  base_rmse  train_rmse  test_rmse  unseen_rmse  \\\n",
       "0 -5.166856 -45.947541  14.673704   22.545295  36.439436    68.912794   \n",
       "1 -0.692976 -26.473834  10.436395   10.332903  13.579255    41.811389   \n",
       "\n",
       "   train_r2_overfit  train_rmse_overfit  unseen_r2_overfit  \\\n",
       "0              True                True              False   \n",
       "1              True                True              False   \n",
       "\n",
       "   unseen_rmse_overfit  \n",
       "0                False  \n",
       "1                False  "
      ]
     },
     "execution_count": 1552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dataframe of final scores\n",
    "# Merge join score dataframe to showcase the final statistics for each of the final models per route\n",
    "final_score_df = join_score.merge(scoring_df, left_on=['model_order', 'route'], right_on=['model_order', 'route'], how='left')\n",
    "final_score_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's look to see how we improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 1553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many models outperformed the baseline models initially?\n",
    "len(initial_score_df[initial_score_df['base_r2'] < initial_score_df['test_r2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 1554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many model predictions outperformed the baseline model?\n",
    "len(initial_score_df[(initial_score_df['base_r2'] < initial_score_df['test_r2']) & (initial_score_df['base_r2'] < initial_score_df['unseen_r2'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the above 93 of our models outperformed the baseline model\n",
    "- Of those 93 models, 75 of the predictions made on unseen data outperforms the baseline models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_order', 'linear_model', 'route', 'base_r2', 'train_r2',\n",
       "       'test_r2', 'unseen_r2', 'base_rmse', 'train_rmse', 'test_rmse',\n",
       "       'unseen_rmse', 'train_r2_overfit', 'train_rmse_overfit',\n",
       "       'unseen_r2_overfit', 'unseen_rmse_overfit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_score_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_order</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.197525e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_r2</th>\n",
       "      <td>5.496154e-19</td>\n",
       "      <td>5.496154e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>6.404712e-01</td>\n",
       "      <td>5.151762e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>-1.132155e+01</td>\n",
       "      <td>-5.721649e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unseen_r2</th>\n",
       "      <td>-4.734430e+01</td>\n",
       "      <td>-2.555999e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_rmse</th>\n",
       "      <td>1.730232e+01</td>\n",
       "      <td>1.730232e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse</th>\n",
       "      <td>1.094662e+01</td>\n",
       "      <td>1.282957e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_rmse</th>\n",
       "      <td>3.467619e+01</td>\n",
       "      <td>2.906967e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unseen_rmse</th>\n",
       "      <td>5.145863e+01</td>\n",
       "      <td>4.105996e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2_overfit</th>\n",
       "      <td>9.158416e-01</td>\n",
       "      <td>9.232673e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_rmse_overfit</th>\n",
       "      <td>9.554455e-01</td>\n",
       "      <td>9.009901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unseen_r2_overfit</th>\n",
       "      <td>2.178218e-01</td>\n",
       "      <td>2.896040e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unseen_rmse_overfit</th>\n",
       "      <td>2.252475e-01</td>\n",
       "      <td>2.797030e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          initial         final\n",
       "model_order          2.000000e+00  2.197525e+01\n",
       "base_r2              5.496154e-19  5.496154e-19\n",
       "train_r2             6.404712e-01  5.151762e-01\n",
       "test_r2             -1.132155e+01 -5.721649e+00\n",
       "unseen_r2           -4.734430e+01 -2.555999e+01\n",
       "base_rmse            1.730232e+01  1.730232e+01\n",
       "train_rmse           1.094662e+01  1.282957e+01\n",
       "test_rmse            3.467619e+01  2.906967e+01\n",
       "unseen_rmse          5.145863e+01  4.105996e+01\n",
       "train_r2_overfit     9.158416e-01  9.232673e-01\n",
       "train_rmse_overfit   9.554455e-01  9.009901e-01\n",
       "unseen_r2_overfit    2.178218e-01  2.896040e-01\n",
       "unseen_rmse_overfit  2.252475e-01  2.797030e-01"
      ]
     },
     "execution_count": 1556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the before & after data\n",
    "initial = initial_score_df.agg(['mean']).T #2nd row\n",
    "final = final_score_df.agg(['mean']).T #ast row\n",
    "compare = pd.concat([initial, final], axis=1)\n",
    "compare.columns = ['initial', 'final']\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- through feature selection optimizations...\n",
    "    - R2\n",
    "        - train R2 from 0.64 -->> 0.53\n",
    "        - test R2 from -7.54 -->> -4.70\n",
    "        - unseen R2 from -48.0 -->> -25.2\n",
    "    - RMSE\n",
    "        - train RMSE from 11.30 -->> 12.97\n",
    "        - test RMSE from 34.26 -->> 28.96\n",
    "        - unseen RMSE from 51.76 -->> 40.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the routes closer and check out how each scored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train (from train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0-10%: 20 routes\n",
      "\n",
      "['Atlanta, GA - Boston, MA' 'Boston, MA - New York, NY'\n",
      " 'Chicago, IL - Nashville, TN' 'Chicago, IL - Omaha, NE'\n",
      " 'Chicago, IL - St. Louis, MO' 'Cincinnati, OH - Philadelphia, PA'\n",
      " 'Cleveland, OH - Los Angeles, CA' 'Dallas, TX - El Paso, TX'\n",
      " 'Dallas, TX - Kansas City, MO' 'Detroit, MI - St. Louis, MO'\n",
      " 'Houston, TX - Oklahoma City, OK' 'Las Vegas, NV - Los Angeles, CA'\n",
      " 'Las Vegas, NV - Minneapolis, MN' 'Los Angeles, CA - Phoenix, AZ'\n",
      " 'Los Angeles, CA - Reno, NV' 'Memphis, TN - Orlando, FL'\n",
      " 'Minneapolis, MN - Orlando, FL' 'Nashville, TN - Tampa, FL'\n",
      " 'Salt Lake City, UT - St. Louis, MO' 'Seattle, WA - Spokane, WA']\n",
      "\n",
      "R2 Score 10-20%: 42 routes\n",
      "\n",
      "['Atlanta, GA - Memphis, TN' 'Boston, MA - Dallas, TX'\n",
      " 'Charlotte, NC - Dallas, TX' 'Chicago, IL - Las Vegas, NV'\n",
      " 'Chicago, IL - Minneapolis, MN' 'Chicago, IL - Portland, OR'\n",
      " 'Chicago, IL - Tucson, AZ' 'Cincinnati, OH - Orlando, FL'\n",
      " 'Dallas, TX - Jacksonville, FL' 'Dallas, TX - Milwaukee, WI'\n",
      " 'Dallas, TX - Omaha, NE' 'Dallas, TX - Portland, OR'\n",
      " 'Dallas, TX - Tucson, AZ' 'Houston, TX - Nashville, TN'\n",
      " 'Houston, TX - Orlando, FL' 'Houston, TX - San Francisco, CA'\n",
      " 'Houston, TX - Seattle, WA' 'Las Vegas, NV - Milwaukee, WI'\n",
      " 'Las Vegas, NV - Philadelphia, PA' 'Las Vegas, NV - Phoenix, AZ'\n",
      " 'Las Vegas, NV - Reno, NV' 'Los Angeles, CA - Pittsburgh, PA'\n",
      " 'Los Angeles, CA - San Francisco, CA' 'Miami, FL - Pittsburgh, PA'\n",
      " 'Miami, FL - San Francisco, CA' 'Minneapolis, MN - Phoenix, AZ'\n",
      " 'Nashville, TN - New York, NY' 'New Orleans, LA - Washington, DC'\n",
      " 'New York, NY - Pittsburgh, PA' 'New York, NY - Washington, DC'\n",
      " 'Philadelphia, PA - Tampa, FL' 'Phoenix, AZ - Sacramento, CA'\n",
      " 'Phoenix, AZ - Seattle, WA' 'Pittsburgh, PA - San Francisco, CA'\n",
      " 'Pittsburgh, PA - Tampa, FL' 'Portland, OR - Salt Lake City, UT'\n",
      " 'Sacramento, CA - Salt Lake City, UT'\n",
      " 'Salt Lake City, UT - Washington, DC' 'San Francisco, CA - Seattle, WA'\n",
      " 'San Francisco, CA - Washington, DC' 'Seattle, WA - St. Louis, MO'\n",
      " 'St. Louis, MO - Washington, DC']\n",
      "\n",
      "R2 Score 20-30%: 31 routes\n",
      "\n",
      "['Atlanta, GA - Las Vegas, NV' 'Atlanta, GA - Miami, FL'\n",
      " 'Atlanta, GA - Milwaukee, WI' 'Atlanta, GA - New Orleans, LA'\n",
      " 'Atlanta, GA - Portland, OR' 'Atlanta, GA - Seattle, WA'\n",
      " 'Atlanta, GA - St. Louis, MO' 'Boston, MA - Salt Lake City, UT'\n",
      " 'Charlotte, NC - Orlando, FL' 'Chicago, IL - Kansas City, MO'\n",
      " 'Chicago, IL - New York, NY' 'Chicago, IL - Sacramento, CA'\n",
      " 'Chicago, IL - Salt Lake City, UT' 'Chicago, IL - San Antonio, TX'\n",
      " 'Cincinnati, OH - Miami, FL' 'Cleveland, OH - Washington, DC'\n",
      " 'Dallas, TX - Indianapolis, IN' 'Dallas, TX - Raleigh, NC'\n",
      " 'Houston, TX - Salt Lake City, UT' 'Houston, TX - St. Louis, MO'\n",
      " 'Indianapolis, IN - Orlando, FL' 'Las Vegas, NV - Omaha, NE'\n",
      " 'Las Vegas, NV - Sacramento, CA' 'Las Vegas, NV - Salt Lake City, UT'\n",
      " 'Las Vegas, NV - San Antonio, TX' 'Las Vegas, NV - Tucson, AZ'\n",
      " 'Los Angeles, CA - New York, NY' 'Memphis, TN - New York, NY'\n",
      " 'Minneapolis, MN - San Francisco, CA' 'Nashville, TN - Orlando, FL'\n",
      " 'Philadelphia, PA - Pittsburgh, PA']\n",
      "\n",
      "R2 Score 30-40%: 41 routes\n",
      "\n",
      "['Atlanta, GA - Jacksonville, FL' 'Atlanta, GA - Phoenix, AZ'\n",
      " 'Atlanta, GA - Tampa, FL' 'Boston, MA - Cleveland, OH'\n",
      " 'Boston, MA - Houston, TX' 'Chicago, IL - Dallas, TX'\n",
      " 'Chicago, IL - Houston, TX' 'Chicago, IL - Philadelphia, PA'\n",
      " 'Chicago, IL - Washington, DC' 'Cincinnati, OH - Los Angeles, CA'\n",
      " 'Cleveland, OH - Dallas, TX' 'Cleveland, OH - Nashville, TN'\n",
      " 'Cleveland, OH - Phoenix, AZ' 'Cleveland, OH - San Francisco, CA'\n",
      " 'Columbus, OH - Houston, TX' 'Columbus, OH - New York, NY'\n",
      " 'Dallas, TX - Detroit, MI' 'Dallas, TX - Houston, TX'\n",
      " 'Dallas, TX - Las Vegas, NV' 'Dallas, TX - Memphis, TN'\n",
      " 'Dallas, TX - Miami, FL' 'Dallas, TX - San Antonio, TX'\n",
      " 'Dallas, TX - St. Louis, MO' 'Dallas, TX - Tulsa, OK'\n",
      " 'Detroit, MI - Seattle, WA' 'El Paso, TX - Phoenix, AZ'\n",
      " 'Hartford, CT - Minneapolis, MN' 'Houston, TX - New York, NY'\n",
      " 'Indianapolis, IN - Philadelphia, PA' 'Los Angeles, CA - Memphis, TN'\n",
      " 'Los Angeles, CA - Washington, DC' 'Memphis, TN - Washington, DC'\n",
      " 'Miami, FL - Washington, DC' 'Milwaukee, WI - New York, NY'\n",
      " 'Minneapolis, MN - St. Louis, MO' 'New York, NY - Phoenix, AZ'\n",
      " 'Orlando, FL - San Antonio, TX' 'Philadelphia, PA - Phoenix, AZ'\n",
      " 'Philadelphia, PA - St. Louis, MO' 'Phoenix, AZ - St. Louis, MO'\n",
      " 'Portland, OR - Spokane, WA']\n",
      "\n",
      "R2 Score 40-50%: 48 routes\n",
      "\n",
      "['Albany, NY - Orlando, FL' 'Albuquerque, NM - Chicago, IL'\n",
      " 'Atlanta, GA - San Antonio, TX' 'Boston, MA - Milwaukee, WI'\n",
      " 'Boston, MA - Philadelphia, PA' 'Boston, MA - Pittsburgh, PA'\n",
      " 'Boston, MA - Raleigh, NC' 'Charlotte, NC - Detroit, MI'\n",
      " 'Charlotte, NC - New York, NY' 'Charlotte, NC - San Francisco, CA'\n",
      " 'Charlotte, NC - Tampa, FL' 'Chicago, IL - Pittsburgh, PA'\n",
      " 'Chicago, IL - Tampa, FL' 'Columbus, OH - Las Vegas, NV'\n",
      " 'Columbus, OH - Minneapolis, MN' 'Columbus, OH - Philadelphia, PA'\n",
      " 'Columbus, OH - Phoenix, AZ' 'Columbus, OH - Washington, DC'\n",
      " 'Dallas, TX - Minneapolis, MN' 'Dallas, TX - Nashville, TN'\n",
      " 'Dallas, TX - Philadelphia, PA' 'Dallas, TX - Phoenix, AZ'\n",
      " 'Dallas, TX - San Francisco, CA' 'Detroit, MI - Hartford, CT'\n",
      " 'Detroit, MI - Nashville, TN' 'Detroit, MI - Orlando, FL'\n",
      " 'Detroit, MI - San Francisco, CA' 'Houston, TX - Miami, FL'\n",
      " 'Houston, TX - Philadelphia, PA' 'Jacksonville, FL - Philadelphia, PA'\n",
      " 'Kansas City, MO - Las Vegas, NV' 'Kansas City, MO - Phoenix, AZ'\n",
      " 'Kansas City, MO - Washington, DC' 'Los Angeles, CA - Miami, FL'\n",
      " 'Los Angeles, CA - St. Louis, MO' 'Los Angeles, CA - Tucson, AZ'\n",
      " 'Memphis, TN - Miami, FL' 'Miami, FL - New York, NY'\n",
      " 'Miami, FL - Orlando, FL' 'Miami, FL - Philadelphia, PA'\n",
      " 'Minneapolis, MN - Nashville, TN' 'New York, NY - Orlando, FL'\n",
      " 'New York, NY - Richmond, VA' 'New York, NY - San Francisco, CA'\n",
      " 'New York, NY - Seattle, WA' 'Orlando, FL - Phoenix, AZ'\n",
      " 'Phoenix, AZ - Portland, OR' 'Phoenix, AZ - Salt Lake City, UT']\n",
      "\n",
      "R2 Score 50-60%: 41 routes\n",
      "\n",
      "['Atlanta, GA - Chicago, IL' 'Atlanta, GA - Detroit, MI'\n",
      " 'Atlanta, GA - Los Angeles, CA' 'Atlanta, GA - Philadelphia, PA'\n",
      " 'Atlanta, GA - Raleigh, NC' 'Austin, TX - Las Vegas, NV'\n",
      " 'Austin, TX - Phoenix, AZ' 'Boston, MA - Chicago, IL'\n",
      " 'Boston, MA - Richmond, VA' 'Boston, MA - San Francisco, CA'\n",
      " 'Boston, MA - St. Louis, MO' 'Charlotte, NC - Miami, FL'\n",
      " 'Charlotte, NC - Philadelphia, PA' 'Chicago, IL - New Orleans, LA'\n",
      " 'Chicago, IL - Oklahoma City, OK' 'Chicago, IL - Richmond, VA'\n",
      " 'Chicago, IL - San Francisco, CA' 'Chicago, IL - Seattle, WA'\n",
      " 'Dallas, TX - Pittsburgh, PA' 'Dallas, TX - Richmond, VA'\n",
      " 'Dallas, TX - Washington, DC' 'Detroit, MI - Miami, FL'\n",
      " 'Hartford, CT - Orlando, FL' 'Houston, TX - Indianapolis, IN'\n",
      " 'Houston, TX - Los Angeles, CA' 'Indianapolis, IN - Las Vegas, NV'\n",
      " 'Indianapolis, IN - Minneapolis, MN' 'Indianapolis, IN - New York, NY'\n",
      " 'Indianapolis, IN - Tampa, FL' 'Las Vegas, NV - New York, NY'\n",
      " 'Las Vegas, NV - Pittsburgh, PA' 'Las Vegas, NV - Tampa, FL'\n",
      " 'Los Angeles, CA - Minneapolis, MN'\n",
      " 'Los Angeles, CA - Salt Lake City, UT'\n",
      " 'Los Angeles, CA - San Antonio, TX' 'Milwaukee, WI - Orlando, FL'\n",
      " 'Minneapolis, MN - Philadelphia, PA' 'Nashville, TN - Philadelphia, PA'\n",
      " 'Orlando, FL - Raleigh, NC' 'Orlando, FL - Washington, DC'\n",
      " 'Raleigh, NC - Washington, DC']\n",
      "\n",
      "R2 Score 60-70%: 36 routes\n",
      "\n",
      "['Albuquerque, NM - Phoenix, AZ' 'Atlanta, GA - Orlando, FL'\n",
      " 'Atlanta, GA - Salt Lake City, UT' 'Austin, TX - Dallas, TX'\n",
      " 'Charlotte, NC - Los Angeles, CA' 'Charlotte, NC - Minneapolis, MN'\n",
      " 'Charlotte, NC - Washington, DC' 'Chicago, IL - Cincinnati, OH'\n",
      " 'Chicago, IL - Orlando, FL' 'Chicago, IL - Phoenix, AZ'\n",
      " 'Cleveland, OH - New York, NY' 'Dallas, TX - Los Angeles, CA'\n",
      " 'Dallas, TX - Lubbock, TX' 'Dallas, TX - New York, NY'\n",
      " 'Dallas, TX - Sacramento, CA' 'Dallas, TX - Seattle, WA'\n",
      " 'Detroit, MI - Los Angeles, CA' 'Detroit, MI - Philadelphia, PA'\n",
      " 'Detroit, MI - Raleigh, NC' 'Houston, TX - Kansas City, MO'\n",
      " 'Houston, TX - Minneapolis, MN' 'Las Vegas, NV - San Francisco, CA'\n",
      " 'Las Vegas, NV - Seattle, WA' 'Miami, FL - Raleigh, NC'\n",
      " 'Miami, FL - St. Louis, MO' 'Minneapolis, MN - New York, NY'\n",
      " 'Minneapolis, MN - Portland, OR' 'New York, NY - Rochester, NY'\n",
      " 'New York, NY - Salt Lake City, UT' 'New York, NY - St. Louis, MO'\n",
      " 'Orlando, FL - Pittsburgh, PA' 'Orlando, FL - San Francisco, CA'\n",
      " 'Phoenix, AZ - Pittsburgh, PA' 'Phoenix, AZ - Washington, DC'\n",
      " 'San Francisco, CA - St. Louis, MO' 'Seattle, WA - Washington, DC']\n",
      "\n",
      "R2 Score 70-80%: 24 routes\n",
      "\n",
      "['Albany, NY - Chicago, IL' 'Atlanta, GA - Charlotte, NC'\n",
      " 'Atlanta, GA - New York, NY' 'Atlanta, GA - Richmond, VA'\n",
      " 'Buffalo, NY - Chicago, IL' 'Buffalo, NY - New York, NY'\n",
      " 'Charlotte, NC - Houston, TX' 'Chicago, IL - Los Angeles, CA'\n",
      " 'Columbus, OH - Dallas, TX' 'Columbus, OH - Orlando, FL'\n",
      " 'Detroit, MI - Kansas City, MO' 'Houston, TX - Washington, DC'\n",
      " 'Los Angeles, CA - Philadelphia, PA' 'Los Angeles, CA - Portland, OR'\n",
      " 'Los Angeles, CA - Seattle, WA' 'Minneapolis, MN - Washington, DC'\n",
      " 'New Orleans, LA - New York, NY' 'Orlando, FL - Philadelphia, PA'\n",
      " 'Philadelphia, PA - Raleigh, NC' 'Philadelphia, PA - San Francisco, CA'\n",
      " 'Phoenix, AZ - Reno, NV' 'Phoenix, AZ - San Francisco, CA'\n",
      " 'Portland, OR - Seattle, WA' 'Salt Lake City, UT - San Francisco, CA']\n",
      "\n",
      "R2 Score 80-90%: 22 routes\n",
      "\n",
      "['Albuquerque, NM - Las Vegas, NV' 'Atlanta, GA - Indianapolis, IN'\n",
      " 'Atlanta, GA - Washington, DC' 'Austin, TX - Chicago, IL'\n",
      " 'Austin, TX - Nashville, TN' 'Boston, MA - Charlotte, NC'\n",
      " 'Chicago, IL - Hartford, CT' 'Chicago, IL - Miami, FL'\n",
      " 'Dallas, TX - Little Rock, AR' 'Detroit, MI - Houston, TX'\n",
      " 'El Paso, TX - Los Angeles, CA' 'Hartford, CT - Washington, DC'\n",
      " 'Kansas City, MO - Minneapolis, MN' 'Kansas City, MO - Philadelphia, PA'\n",
      " 'Los Angeles, CA - Sacramento, CA' 'Minneapolis, MN - Raleigh, NC'\n",
      " 'New York, NY - Tampa, FL' 'Pittsburgh, PA - Washington, DC'\n",
      " 'Portland, OR - Reno, NV' 'Reno, NV - Seattle, WA'\n",
      " 'Salt Lake City, UT - Seattle, WA' 'Tampa, FL - Washington, DC']\n",
      "\n",
      "R2 Score 90-100%: 76 routes\n",
      "\n",
      "['Albuquerque, NM - Dallas, TX' 'Albuquerque, NM - Houston, TX'\n",
      " 'Atlanta, GA - Austin, TX' 'Atlanta, GA - Buffalo, NY'\n",
      " 'Atlanta, GA - Cincinnati, OH' 'Atlanta, GA - Cleveland, OH'\n",
      " 'Atlanta, GA - Columbus, OH' 'Atlanta, GA - Dallas, TX'\n",
      " 'Atlanta, GA - Hartford, CT' 'Atlanta, GA - Houston, TX'\n",
      " 'Atlanta, GA - Kansas City, MO' 'Atlanta, GA - San Francisco, CA'\n",
      " 'Austin, TX - El Paso, TX' 'Austin, TX - Houston, TX'\n",
      " 'Boston, MA - Cincinnati, OH' 'Boston, MA - Columbus, OH'\n",
      " 'Boston, MA - Detroit, MI' 'Boston, MA - Las Vegas, NV'\n",
      " 'Boston, MA - Los Angeles, CA' 'Boston, MA - Minneapolis, MN'\n",
      " 'Boston, MA - Orlando, FL' 'Boston, MA - Washington, DC'\n",
      " 'Buffalo, NY - Orlando, FL' 'Charlotte, NC - Chicago, IL'\n",
      " 'Chicago, IL - Cleveland, OH' 'Chicago, IL - Columbus, OH'\n",
      " 'Chicago, IL - Detroit, MI' 'Chicago, IL - Indianapolis, IN'\n",
      " 'Chicago, IL - Memphis, TN' 'Chicago, IL - Raleigh, NC'\n",
      " 'Cincinnati, OH - New York, NY' 'Cincinnati, OH - San Francisco, CA'\n",
      " 'Cincinnati, OH - Tampa, FL' 'Cincinnati, OH - Washington, DC'\n",
      " 'Cleveland, OH - Houston, TX' 'Cleveland, OH - Las Vegas, NV'\n",
      " 'Cleveland, OH - Miami, FL' 'Cleveland, OH - Orlando, FL'\n",
      " 'Colorado Springs, CO - Dallas, TX' 'Columbus, OH - Tampa, FL'\n",
      " 'Dallas, TX - New Orleans, LA' 'Dallas, TX - Orlando, FL'\n",
      " 'Dallas, TX - Salt Lake City, UT' 'Dallas, TX - Tampa, FL'\n",
      " 'Detroit, MI - Las Vegas, NV' 'Detroit, MI - Minneapolis, MN'\n",
      " 'Detroit, MI - New York, NY' 'Detroit, MI - Phoenix, AZ'\n",
      " 'Detroit, MI - Tampa, FL' 'El Paso, TX - Houston, TX'\n",
      " 'El Paso, TX - San Antonio, TX' 'Hartford, CT - Miami, FL'\n",
      " 'Houston, TX - Las Vegas, NV' 'Houston, TX - New Orleans, LA'\n",
      " 'Houston, TX - Phoenix, AZ' 'Houston, TX - San Antonio, TX'\n",
      " 'Houston, TX - Tampa, FL' 'Houston, TX - Tulsa, OK'\n",
      " 'Jacksonville, FL - New York, NY' 'Kansas City, MO - Los Angeles, CA'\n",
      " 'Kansas City, MO - New York, NY' 'Las Vegas, NV - Nashville, TN'\n",
      " 'Las Vegas, NV - St. Louis, MO' 'Los Angeles, CA - Nashville, TN'\n",
      " 'Los Angeles, CA - Orlando, FL' 'Milwaukee, WI - Phoenix, AZ'\n",
      " 'Milwaukee, WI - Washington, DC' 'Minneapolis, MN - Seattle, WA'\n",
      " 'Nashville, TN - San Antonio, TX' 'New York, NY - Raleigh, NC'\n",
      " 'Orlando, FL - Salt Lake City, UT' 'Orlando, FL - St. Louis, MO'\n",
      " 'Phoenix, AZ - San Antonio, TX' 'Portland, OR - Sacramento, CA'\n",
      " 'Sacramento, CA - Seattle, WA' 'St. Louis, MO - Tampa, FL']\n",
      "\n",
      "0 routes above 100%\n",
      "23 routes below 0%\n",
      "381 total routes scoring between 0-100%\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the routes and their scoring!\n",
    "count = 0\n",
    "for i in range(0, 10):\n",
    "    length = len(final_score_df[(final_score_df['train_r2'] > (i/10)) & (final_score_df['train_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print(f'R2 Score {int((i/10)*100)}-{int((i+1)/10*100)}%: {length} routes')\n",
    "    count += length\n",
    "    print()\n",
    "    print(final_score_df[(final_score_df['train_r2'] > (i/10)) & (final_score_df['train_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print()\n",
    "    i_count += i\n",
    "\n",
    "train_above_1 = len(final_score_df[final_score_df['train_r2'] > 1])\n",
    "train_below_0 = len(final_score_df[final_score_df['train_r2'] <= 0])\n",
    "print(f'{train_above_1} routes above 100%')\n",
    "print(f'{train_below_0} routes below 0%')\n",
    "print(f'{count} total routes scoring between 0-100%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test (from train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0-10%: 4 routes\n",
      "\n",
      "['Atlanta, GA - Portland, OR' 'Indianapolis, IN - Minneapolis, MN'\n",
      " 'Las Vegas, NV - Philadelphia, PA' 'Los Angeles, CA - Sacramento, CA']\n",
      "\n",
      "R2 Score 10-20%: 8 routes\n",
      "\n",
      "['Atlanta, GA - Washington, DC' 'Columbus, OH - New York, NY'\n",
      " 'Dallas, TX - Detroit, MI' 'El Paso, TX - Los Angeles, CA'\n",
      " 'Jacksonville, FL - Philadelphia, PA' 'Miami, FL - New York, NY'\n",
      " 'Milwaukee, WI - Washington, DC' 'Phoenix, AZ - Reno, NV']\n",
      "\n",
      "R2 Score 20-30%: 1 routes\n",
      "\n",
      "['Boston, MA - Pittsburgh, PA']\n",
      "\n",
      "R2 Score 30-40%: 6 routes\n",
      "\n",
      "['Atlanta, GA - Orlando, FL' 'Austin, TX - Las Vegas, NV'\n",
      " 'Austin, TX - Nashville, TN' 'Detroit, MI - Orlando, FL'\n",
      " 'Los Angeles, CA - Seattle, WA' 'Salt Lake City, UT - Washington, DC']\n",
      "\n",
      "R2 Score 40-50%: 6 routes\n",
      "\n",
      "['Charlotte, NC - Minneapolis, MN' 'Chicago, IL - Las Vegas, NV'\n",
      " 'Detroit, MI - Miami, FL' 'Hartford, CT - Orlando, FL'\n",
      " 'Minneapolis, MN - Raleigh, NC' 'Sacramento, CA - Seattle, WA']\n",
      "\n",
      "R2 Score 50-60%: 3 routes\n",
      "\n",
      "['Atlanta, GA - Chicago, IL' 'Dallas, TX - Richmond, VA'\n",
      " 'Kansas City, MO - New York, NY']\n",
      "\n",
      "R2 Score 60-70%: 1 routes\n",
      "\n",
      "['Cleveland, OH - Orlando, FL']\n",
      "\n",
      "R2 Score 70-80%: 2 routes\n",
      "\n",
      "['Boston, MA - Charlotte, NC' 'Minneapolis, MN - Washington, DC']\n",
      "\n",
      "R2 Score 80-90%: 5 routes\n",
      "\n",
      "['Buffalo, NY - Chicago, IL' 'Chicago, IL - Memphis, TN'\n",
      " 'Columbus, OH - Tampa, FL' 'Dallas, TX - Orlando, FL'\n",
      " 'Los Angeles, CA - Orlando, FL']\n",
      "\n",
      "R2 Score 90-100%: 62 routes\n",
      "\n",
      "['Albuquerque, NM - Dallas, TX' 'Albuquerque, NM - Houston, TX'\n",
      " 'Atlanta, GA - Austin, TX' 'Atlanta, GA - Buffalo, NY'\n",
      " 'Atlanta, GA - Cincinnati, OH' 'Atlanta, GA - Cleveland, OH'\n",
      " 'Atlanta, GA - Columbus, OH' 'Atlanta, GA - Dallas, TX'\n",
      " 'Atlanta, GA - Hartford, CT' 'Atlanta, GA - Houston, TX'\n",
      " 'Atlanta, GA - Kansas City, MO' 'Austin, TX - El Paso, TX'\n",
      " 'Austin, TX - Houston, TX' 'Boston, MA - Cincinnati, OH'\n",
      " 'Boston, MA - Columbus, OH' 'Boston, MA - Detroit, MI'\n",
      " 'Boston, MA - Las Vegas, NV' 'Boston, MA - Minneapolis, MN'\n",
      " 'Boston, MA - Orlando, FL' 'Boston, MA - Washington, DC'\n",
      " 'Chicago, IL - Cleveland, OH' 'Chicago, IL - Columbus, OH'\n",
      " 'Chicago, IL - Detroit, MI' 'Chicago, IL - Indianapolis, IN'\n",
      " 'Chicago, IL - Raleigh, NC' 'Cincinnati, OH - New York, NY'\n",
      " 'Cincinnati, OH - San Francisco, CA' 'Cincinnati, OH - Tampa, FL'\n",
      " 'Cincinnati, OH - Washington, DC' 'Cleveland, OH - Houston, TX'\n",
      " 'Cleveland, OH - Las Vegas, NV' 'Cleveland, OH - Miami, FL'\n",
      " 'Colorado Springs, CO - Dallas, TX' 'Dallas, TX - Salt Lake City, UT'\n",
      " 'Dallas, TX - Tampa, FL' 'Detroit, MI - Las Vegas, NV'\n",
      " 'Detroit, MI - Minneapolis, MN' 'Detroit, MI - New York, NY'\n",
      " 'Detroit, MI - Phoenix, AZ' 'Detroit, MI - Tampa, FL'\n",
      " 'El Paso, TX - Houston, TX' 'El Paso, TX - San Antonio, TX'\n",
      " 'Hartford, CT - Miami, FL' 'Houston, TX - Las Vegas, NV'\n",
      " 'Houston, TX - Phoenix, AZ' 'Houston, TX - San Antonio, TX'\n",
      " 'Houston, TX - Tampa, FL' 'Houston, TX - Tulsa, OK'\n",
      " 'Jacksonville, FL - New York, NY' 'Kansas City, MO - Los Angeles, CA'\n",
      " 'Las Vegas, NV - Nashville, TN' 'Las Vegas, NV - St. Louis, MO'\n",
      " 'Los Angeles, CA - Nashville, TN' 'Milwaukee, WI - Phoenix, AZ'\n",
      " 'Minneapolis, MN - Seattle, WA' 'Nashville, TN - San Antonio, TX'\n",
      " 'New York, NY - Raleigh, NC' 'Orlando, FL - Salt Lake City, UT'\n",
      " 'Orlando, FL - St. Louis, MO' 'Phoenix, AZ - San Antonio, TX'\n",
      " 'Portland, OR - Sacramento, CA' 'St. Louis, MO - Tampa, FL']\n",
      "\n",
      "0 routes above 100%\n",
      "306 routes below 0%\n",
      "98 total routes scoring between 0-100%\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the routes and their scoring!\n",
    "count = 0\n",
    "for i in range(0, 10):\n",
    "    length = len(final_score_df[(final_score_df['test_r2'] > (i/10)) & (final_score_df['test_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print(f'R2 Score {int((i/10)*100)}-{int((i+1)/10*100)}%: {length} routes')\n",
    "    count += length\n",
    "    print()\n",
    "    print(final_score_df[(final_score_df['test_r2'] > (i/10)) & (final_score_df['test_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print()\n",
    "    i_count += i\n",
    "\n",
    "test_above_1 = len(final_score_df[final_score_df['test_r2'] > 1])\n",
    "test_below_0 = len(final_score_df[final_score_df['test_r2'] <= 0])\n",
    "print(f'{test_above_1} routes above 100%')\n",
    "print(f'{test_below_0} routes below 0%')\n",
    "print(f'{count} total routes scoring between 0-100%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score 0-10%: 6 routes\n",
      "\n",
      "['Boston, MA - Raleigh, NC' 'Cincinnati, OH - Los Angeles, CA'\n",
      " 'Cincinnati, OH - Orlando, FL' 'Dallas, TX - Raleigh, NC'\n",
      " 'Kansas City, MO - New York, NY' 'Memphis, TN - New York, NY']\n",
      "\n",
      "R2 Score 10-20%: 5 routes\n",
      "\n",
      "['Chicago, IL - Cincinnati, OH' 'Chicago, IL - Tampa, FL'\n",
      " 'Indianapolis, IN - Minneapolis, MN' 'Miami, FL - Washington, DC'\n",
      " 'Orlando, FL - San Francisco, CA']\n",
      "\n",
      "R2 Score 20-30%: 2 routes\n",
      "\n",
      "['Indianapolis, IN - New York, NY' 'Minneapolis, MN - Nashville, TN']\n",
      "\n",
      "R2 Score 30-40%: 1 routes\n",
      "\n",
      "['Houston, TX - Minneapolis, MN']\n",
      "\n",
      "R2 Score 40-50%: 1 routes\n",
      "\n",
      "['Boston, MA - Los Angeles, CA']\n",
      "\n",
      "R2 Score 50-60%: 1 routes\n",
      "\n",
      "['Chicago, IL - Raleigh, NC']\n",
      "\n",
      "R2 Score 60-70%: 1 routes\n",
      "\n",
      "['Atlanta, GA - Chicago, IL']\n",
      "\n",
      "R2 Score 70-80%: 0 routes\n",
      "\n",
      "[]\n",
      "\n",
      "R2 Score 80-90%: 2 routes\n",
      "\n",
      "['Los Angeles, CA - Orlando, FL' 'Orlando, FL - Salt Lake City, UT']\n",
      "\n",
      "R2 Score 90-100%: 62 routes\n",
      "\n",
      "['Albuquerque, NM - Dallas, TX' 'Albuquerque, NM - Houston, TX'\n",
      " 'Atlanta, GA - Austin, TX' 'Atlanta, GA - Buffalo, NY'\n",
      " 'Atlanta, GA - Cincinnati, OH' 'Atlanta, GA - Cleveland, OH'\n",
      " 'Atlanta, GA - Columbus, OH' 'Atlanta, GA - Dallas, TX'\n",
      " 'Atlanta, GA - Hartford, CT' 'Atlanta, GA - Houston, TX'\n",
      " 'Atlanta, GA - Kansas City, MO' 'Austin, TX - El Paso, TX'\n",
      " 'Austin, TX - Houston, TX' 'Boston, MA - Cincinnati, OH'\n",
      " 'Boston, MA - Columbus, OH' 'Boston, MA - Detroit, MI'\n",
      " 'Boston, MA - Las Vegas, NV' 'Boston, MA - Minneapolis, MN'\n",
      " 'Boston, MA - Orlando, FL' 'Boston, MA - Washington, DC'\n",
      " 'Chicago, IL - Cleveland, OH' 'Chicago, IL - Columbus, OH'\n",
      " 'Chicago, IL - Detroit, MI' 'Chicago, IL - Indianapolis, IN'\n",
      " 'Chicago, IL - Memphis, TN' 'Cincinnati, OH - New York, NY'\n",
      " 'Cincinnati, OH - San Francisco, CA' 'Cincinnati, OH - Tampa, FL'\n",
      " 'Cincinnati, OH - Washington, DC' 'Cleveland, OH - Houston, TX'\n",
      " 'Cleveland, OH - Las Vegas, NV' 'Cleveland, OH - Miami, FL'\n",
      " 'Colorado Springs, CO - Dallas, TX' 'Dallas, TX - Orlando, FL'\n",
      " 'Dallas, TX - Salt Lake City, UT' 'Dallas, TX - Tampa, FL'\n",
      " 'Detroit, MI - Las Vegas, NV' 'Detroit, MI - Minneapolis, MN'\n",
      " 'Detroit, MI - New York, NY' 'Detroit, MI - Phoenix, AZ'\n",
      " 'Detroit, MI - Tampa, FL' 'El Paso, TX - Houston, TX'\n",
      " 'El Paso, TX - San Antonio, TX' 'Hartford, CT - Miami, FL'\n",
      " 'Houston, TX - Las Vegas, NV' 'Houston, TX - Phoenix, AZ'\n",
      " 'Houston, TX - San Antonio, TX' 'Houston, TX - Tampa, FL'\n",
      " 'Houston, TX - Tulsa, OK' 'Jacksonville, FL - New York, NY'\n",
      " 'Kansas City, MO - Los Angeles, CA' 'Las Vegas, NV - Nashville, TN'\n",
      " 'Las Vegas, NV - St. Louis, MO' 'Los Angeles, CA - Nashville, TN'\n",
      " 'Milwaukee, WI - Phoenix, AZ' 'Minneapolis, MN - Seattle, WA'\n",
      " 'Nashville, TN - San Antonio, TX' 'New York, NY - Raleigh, NC'\n",
      " 'Orlando, FL - St. Louis, MO' 'Phoenix, AZ - San Antonio, TX'\n",
      " 'Portland, OR - Sacramento, CA' 'St. Louis, MO - Tampa, FL']\n",
      "\n",
      "0 routes above 100%\n",
      "323 routes below 0%\n",
      "81 total routes scoring between 0-100%\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the routes and their scoring!\n",
    "count = 0\n",
    "for i in range(0, 10):\n",
    "    length = len(final_score_df[(final_score_df['unseen_r2'] > (i/10)) & (final_score_df['unseen_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print(f'R2 Score {int((i/10)*100)}-{int((i+1)/10*100)}%: {length} routes')\n",
    "    count += length\n",
    "    print()\n",
    "    print(final_score_df[(final_score_df['unseen_r2'] > (i/10)) & (final_score_df['unseen_r2'] <= ((i+1)/10))]['route'].unique())\n",
    "    print()\n",
    "    i_count += i\n",
    "\n",
    "unseen_above_1 = len(final_score_df[final_score_df['unseen_r2'] > 1])\n",
    "unseen_below_0 = len(final_score_df[final_score_df['unseen_r2'] <= 0])\n",
    "print(f'{unseen_above_1} routes above 100%')\n",
    "print(f'{unseen_below_0} routes below 0%')\n",
    "print(f'{count} total routes scoring between 0-100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at where we started and where we ended!\n",
    "\n",
    "initial_train_r2 = []\n",
    "initial_train_rmse = []\n",
    "for path in list(all_route_dict.keys()):\n",
    "    if all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['train_r2'] > 0:\n",
    "        initial_train_r2.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['train_r2'])\n",
    "        initial_train_rmse.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['train_rmse'])\n",
    "    \n",
    "final_train_r2 = []\n",
    "final_train_rmse = []\n",
    "for path in list(all_route_dict.keys()):\n",
    "    if all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['train_r2'] > 0:\n",
    "        final_train_r2.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['train_r2'])\n",
    "        final_train_rmse.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['train_rmse'])\n",
    "        \n",
    "initial_test_r2 = []\n",
    "initial_test_rmse = []\n",
    "for path in list(all_route_dict.keys()):\n",
    "    if all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['test_r2'] > 0:\n",
    "        initial_test_r2.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['test_r2'])\n",
    "        initial_test_rmse.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['test_rmse'])\n",
    "    \n",
    "final_test_r2 = []\n",
    "final_test_rmse = []\n",
    "for path in list(all_route_dict.keys()):\n",
    "    if all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['test_r2'] > 0:\n",
    "        final_test_r2.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['test_r2'])\n",
    "        final_test_rmse.append(all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['test_rmse'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the changes from where we started to where we went, you'll notice scores did in fact go up, however, as noted earlier we exceeding baseline scores significantly off of the bat.  In the future we should look to find better ways to tune our model in order to reduce overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Initial Train R2 Average: 0.6404712401892289\n",
      "Overall Final Train R2 Average: 0.5462760462962177\n",
      "Overall Initial Test R2 Average: 0.8479141175858956\n",
      "Overall Final Test R2 Average: 0.7757444879470826\n",
      "\n",
      "Overall Initial Train RMSE Average: 10.9466150305228\n",
      "Overall Final Train RMSE Average: 12.226174003620205\n",
      "Overall Initial Test RMSE Average: 3.395936479562116\n",
      "Overall Final Test RMSE Average: 5.290230018045353\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall Initial Train R2 Average: {np.mean(initial_train_r2)}')\n",
    "print(f'Overall Final Train R2 Average: {np.mean(final_train_r2)}')\n",
    "print(f'Overall Initial Test R2 Average: {np.mean(initial_test_r2)}')\n",
    "print(f'Overall Final Test R2 Average: {np.mean(final_test_r2)}')\n",
    "print()\n",
    "print(f'Overall Initial Train RMSE Average: {np.mean(initial_train_rmse)}')\n",
    "print(f'Overall Final Train RMSE Average: {np.mean(final_train_rmse)}')\n",
    "print(f'Overall Initial Test RMSE Average: {np.mean(initial_test_rmse)}')\n",
    "print(f'Overall Final Test RMSE Average: {np.mean(final_test_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>initial_train_r2</th>\n",
       "      <th>final_train_r2</th>\n",
       "      <th>initial_test_r2</th>\n",
       "      <th>final_test_r2</th>\n",
       "      <th>initial_train_rmse</th>\n",
       "      <th>final_train_rmse</th>\n",
       "      <th>initial_test_rmse</th>\n",
       "      <th>final_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>0.76573</td>\n",
       "      <td>0.732433</td>\n",
       "      <td>-11.2114</td>\n",
       "      <td>-5.16686</td>\n",
       "      <td>21.0959</td>\n",
       "      <td>22.5453</td>\n",
       "      <td>51.2771</td>\n",
       "      <td>36.4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>0.531803</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>-1.39964</td>\n",
       "      <td>-0.692976</td>\n",
       "      <td>9.25274</td>\n",
       "      <td>10.3329</td>\n",
       "      <td>16.1668</td>\n",
       "      <td>13.5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albuquerque, NM - Chicago, IL</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>0.415028</td>\n",
       "      <td>-2.56934</td>\n",
       "      <td>-0.577167</td>\n",
       "      <td>8.39041</td>\n",
       "      <td>9.11637</td>\n",
       "      <td>25.179</td>\n",
       "      <td>16.7372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albuquerque, NM - Dallas, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80657e-12</td>\n",
       "      <td>3.1308e-14</td>\n",
       "      <td>3.50712e-12</td>\n",
       "      <td>7.12907e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albuquerque, NM - Houston, TX</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.0176341</td>\n",
       "      <td>0.0208618</td>\n",
       "      <td>0.0499627</td>\n",
       "      <td>0.0291183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Seattle, WA - St. Louis, MO</td>\n",
       "      <td>0.387131</td>\n",
       "      <td>0.127598</td>\n",
       "      <td>-22.2179</td>\n",
       "      <td>-2.30261</td>\n",
       "      <td>24.7768</td>\n",
       "      <td>29.561</td>\n",
       "      <td>82.4328</td>\n",
       "      <td>31.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Seattle, WA - Washington, DC</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.666804</td>\n",
       "      <td>-2.47563</td>\n",
       "      <td>-1.98754</td>\n",
       "      <td>13.0253</td>\n",
       "      <td>14.0076</td>\n",
       "      <td>34.8948</td>\n",
       "      <td>32.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>St. Louis, MO - Tampa, FL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.51266e-08</td>\n",
       "      <td>5.90224e-08</td>\n",
       "      <td>0.00162509</td>\n",
       "      <td>0.00162508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>St. Louis, MO - Washington, DC</td>\n",
       "      <td>0.365395</td>\n",
       "      <td>0.153563</td>\n",
       "      <td>-5.89367</td>\n",
       "      <td>-3.22371</td>\n",
       "      <td>10.4563</td>\n",
       "      <td>12.076</td>\n",
       "      <td>30.6791</td>\n",
       "      <td>24.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Tampa, FL - Washington, DC</td>\n",
       "      <td>0.846174</td>\n",
       "      <td>0.818378</td>\n",
       "      <td>-2.49693</td>\n",
       "      <td>-3.30325</td>\n",
       "      <td>3.79554</td>\n",
       "      <td>4.12423</td>\n",
       "      <td>19.8806</td>\n",
       "      <td>22.0538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              route initial_train_r2 final_train_r2  \\\n",
       "0          Albany, NY - Chicago, IL          0.76573       0.732433   \n",
       "1          Albany, NY - Orlando, FL         0.531803       0.416107   \n",
       "2     Albuquerque, NM - Chicago, IL         0.504485       0.415028   \n",
       "3      Albuquerque, NM - Dallas, TX                1              1   \n",
       "4     Albuquerque, NM - Houston, TX         0.999997       0.999996   \n",
       "..                              ...              ...            ...   \n",
       "399     Seattle, WA - St. Louis, MO         0.387131       0.127598   \n",
       "400    Seattle, WA - Washington, DC         0.711897       0.666804   \n",
       "401       St. Louis, MO - Tampa, FL                1              1   \n",
       "402  St. Louis, MO - Washington, DC         0.365395       0.153563   \n",
       "403      Tampa, FL - Washington, DC         0.846174       0.818378   \n",
       "\n",
       "    initial_test_r2 final_test_r2 initial_train_rmse final_train_rmse  \\\n",
       "0          -11.2114      -5.16686            21.0959          22.5453   \n",
       "1          -1.39964     -0.692976            9.25274          10.3329   \n",
       "2          -2.56934     -0.577167            8.39041          9.11637   \n",
       "3                 1             1        2.80657e-12       3.1308e-14   \n",
       "4          0.999874      0.999957          0.0176341        0.0208618   \n",
       "..              ...           ...                ...              ...   \n",
       "399        -22.2179      -2.30261            24.7768           29.561   \n",
       "400        -2.47563      -1.98754            13.0253          14.0076   \n",
       "401               1             1        8.51266e-08      5.90224e-08   \n",
       "402        -5.89367      -3.22371            10.4563           12.076   \n",
       "403        -2.49693      -3.30325            3.79554          4.12423   \n",
       "\n",
       "    initial_test_rmse final_test_rmse  \n",
       "0             51.2771         36.4394  \n",
       "1             16.1668         13.5793  \n",
       "2              25.179         16.7372  \n",
       "3         3.50712e-12     7.12907e-14  \n",
       "4           0.0499627       0.0291183  \n",
       "..                ...             ...  \n",
       "399           82.4328         31.0897  \n",
       "400           34.8948          32.352  \n",
       "401        0.00162509      0.00162508  \n",
       "402           30.6791          24.014  \n",
       "403           19.8806         22.0538  \n",
       "\n",
       "[404 rows x 9 columns]"
      ]
     },
     "execution_count": 1562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to view our scores by route\n",
    "\n",
    "route_scores_dict = {}\n",
    "for path in list(all_route_dict.keys()):\n",
    "    only_dict = {}\n",
    "    only_dict['route'] = path\n",
    "    only_dict['initial_train_r2'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['train_r2']\n",
    "    only_dict['final_train_r2'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['train_r2']\n",
    "    only_dict['initial_test_r2'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['test_r2']\n",
    "    only_dict['final_test_r2'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['test_r2']\n",
    "    only_dict['initial_train_rmse'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['train_rmse']\n",
    "    only_dict['final_train_rmse'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['train_rmse']\n",
    "    only_dict['initial_test_rmse'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[0]]['test_rmse']\n",
    "    only_dict['final_test_rmse'] = all_route_dict[path]['analytics'][list(all_route_dict[path]['analytics'].keys())[-1]]['test_rmse']\n",
    "    route_scores_dict[path] = only_dict\n",
    "\n",
    "only_df = pd.DataFrame(route_scores_dict).T.reset_index().drop(columns='index')\n",
    "only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>initial_train_r2</th>\n",
       "      <th>final_train_r2</th>\n",
       "      <th>initial_test_r2</th>\n",
       "      <th>final_test_r2</th>\n",
       "      <th>initial_train_rmse</th>\n",
       "      <th>final_train_rmse</th>\n",
       "      <th>initial_test_rmse</th>\n",
       "      <th>final_test_rmse</th>\n",
       "      <th>initial_r2_spread</th>\n",
       "      <th>final_r2_spread</th>\n",
       "      <th>initial_rmse_spread</th>\n",
       "      <th>final_rmse_spread</th>\n",
       "      <th>test_rmse_improved</th>\n",
       "      <th>test_r2_improved</th>\n",
       "      <th>test_rmse_improvement_%</th>\n",
       "      <th>test_r2_improvement_%</th>\n",
       "      <th>test_rmse_improvement_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>0.76573</td>\n",
       "      <td>0.732433</td>\n",
       "      <td>-11.2114</td>\n",
       "      <td>-5.16686</td>\n",
       "      <td>21.0959</td>\n",
       "      <td>22.5453</td>\n",
       "      <td>51.2771</td>\n",
       "      <td>36.4394</td>\n",
       "      <td>11.9772</td>\n",
       "      <td>5.89929</td>\n",
       "      <td>-30.1812</td>\n",
       "      <td>-13.8941</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.289362</td>\n",
       "      <td>-0.539144</td>\n",
       "      <td>14.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>0.531803</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>-1.39964</td>\n",
       "      <td>-0.692976</td>\n",
       "      <td>9.25274</td>\n",
       "      <td>10.3329</td>\n",
       "      <td>16.1668</td>\n",
       "      <td>13.5793</td>\n",
       "      <td>1.93145</td>\n",
       "      <td>1.10908</td>\n",
       "      <td>-6.91405</td>\n",
       "      <td>-3.24635</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.160052</td>\n",
       "      <td>-0.504891</td>\n",
       "      <td>2.58754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      route initial_train_r2 final_train_r2 initial_test_r2  \\\n",
       "0  Albany, NY - Chicago, IL          0.76573       0.732433        -11.2114   \n",
       "1  Albany, NY - Orlando, FL         0.531803       0.416107        -1.39964   \n",
       "\n",
       "  final_test_r2 initial_train_rmse final_train_rmse initial_test_rmse  \\\n",
       "0      -5.16686            21.0959          22.5453           51.2771   \n",
       "1     -0.692976            9.25274          10.3329           16.1668   \n",
       "\n",
       "  final_test_rmse initial_r2_spread final_r2_spread initial_rmse_spread  \\\n",
       "0         36.4394           11.9772         5.89929            -30.1812   \n",
       "1         13.5793           1.93145         1.10908            -6.91405   \n",
       "\n",
       "  final_rmse_spread  test_rmse_improved  test_r2_improved  \\\n",
       "0          -13.8941                True              True   \n",
       "1          -3.24635                True              True   \n",
       "\n",
       "  test_rmse_improvement_% test_r2_improvement_% test_rmse_improvement_amount  \n",
       "0                0.289362             -0.539144                      14.8376  \n",
       "1                0.160052             -0.504891                      2.58754  "
      ]
     },
     "execution_count": 1563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Engineering Additional features\n",
    "only_df['initial_r2_spread'] = only_df['initial_train_r2'] - only_df['initial_test_r2']\n",
    "only_df['final_r2_spread'] = only_df['final_train_r2'] - only_df['final_test_r2']\n",
    "only_df['initial_rmse_spread'] = only_df['initial_train_rmse'] - only_df['initial_test_rmse']\n",
    "only_df['final_rmse_spread'] = only_df['final_train_rmse'] - only_df['final_test_rmse']\n",
    "only_df['test_rmse_improved'] = only_df['initial_test_rmse'] > only_df['final_test_rmse']\n",
    "only_df['test_r2_improved'] = only_df['initial_test_rmse'] > only_df['final_test_rmse']\n",
    "only_df['test_rmse_improvement_%'] = (only_df['initial_test_rmse'] - only_df['final_test_rmse']) / only_df['initial_test_rmse']\n",
    "only_df['test_r2_improvement_%'] = (only_df['final_test_r2'] - only_df['initial_test_r2']) / only_df['initial_test_r2']\n",
    "only_df['test_rmse_improvement_amount'] = only_df['initial_test_rmse'] - only_df['final_test_rmse']\n",
    "only_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See below how we improved 299 models from the first model until the final model which we looped through to satify the p-value condition of 0.05\n",
    "- again note earlier this does not mean we surpassed baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route</th>\n",
       "      <th>initial_train_r2</th>\n",
       "      <th>final_train_r2</th>\n",
       "      <th>initial_test_r2</th>\n",
       "      <th>final_test_r2</th>\n",
       "      <th>initial_train_rmse</th>\n",
       "      <th>final_train_rmse</th>\n",
       "      <th>initial_test_rmse</th>\n",
       "      <th>final_test_rmse</th>\n",
       "      <th>initial_r2_spread</th>\n",
       "      <th>final_r2_spread</th>\n",
       "      <th>initial_rmse_spread</th>\n",
       "      <th>final_rmse_spread</th>\n",
       "      <th>test_rmse_improved</th>\n",
       "      <th>test_r2_improved</th>\n",
       "      <th>test_rmse_improvement_%</th>\n",
       "      <th>test_r2_improvement_%</th>\n",
       "      <th>test_rmse_improvement_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albany, NY - Chicago, IL</td>\n",
       "      <td>0.76573</td>\n",
       "      <td>0.732433</td>\n",
       "      <td>-11.2114</td>\n",
       "      <td>-5.16686</td>\n",
       "      <td>21.0959</td>\n",
       "      <td>22.5453</td>\n",
       "      <td>51.2771</td>\n",
       "      <td>36.4394</td>\n",
       "      <td>11.9772</td>\n",
       "      <td>5.89929</td>\n",
       "      <td>-30.1812</td>\n",
       "      <td>-13.8941</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.289362</td>\n",
       "      <td>-0.539144</td>\n",
       "      <td>14.8376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albany, NY - Orlando, FL</td>\n",
       "      <td>0.531803</td>\n",
       "      <td>0.416107</td>\n",
       "      <td>-1.39964</td>\n",
       "      <td>-0.692976</td>\n",
       "      <td>9.25274</td>\n",
       "      <td>10.3329</td>\n",
       "      <td>16.1668</td>\n",
       "      <td>13.5793</td>\n",
       "      <td>1.93145</td>\n",
       "      <td>1.10908</td>\n",
       "      <td>-6.91405</td>\n",
       "      <td>-3.24635</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.160052</td>\n",
       "      <td>-0.504891</td>\n",
       "      <td>2.58754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albuquerque, NM - Chicago, IL</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>0.415028</td>\n",
       "      <td>-2.56934</td>\n",
       "      <td>-0.577167</td>\n",
       "      <td>8.39041</td>\n",
       "      <td>9.11637</td>\n",
       "      <td>25.179</td>\n",
       "      <td>16.7372</td>\n",
       "      <td>3.07382</td>\n",
       "      <td>0.992195</td>\n",
       "      <td>-16.7886</td>\n",
       "      <td>-7.62087</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.335271</td>\n",
       "      <td>-0.775364</td>\n",
       "      <td>8.44179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albuquerque, NM - Dallas, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80657e-12</td>\n",
       "      <td>3.1308e-14</td>\n",
       "      <td>3.50712e-12</td>\n",
       "      <td>7.12907e-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.00548e-13</td>\n",
       "      <td>-3.99828e-14</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.979673</td>\n",
       "      <td>0</td>\n",
       "      <td>3.43582e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albuquerque, NM - Houston, TX</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.0176341</td>\n",
       "      <td>0.0208618</td>\n",
       "      <td>0.0499627</td>\n",
       "      <td>0.0291183</td>\n",
       "      <td>0.000123546</td>\n",
       "      <td>3.92844e-05</td>\n",
       "      <td>-0.0323287</td>\n",
       "      <td>-0.00825647</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>8.32619e-05</td>\n",
       "      <td>0.0208444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Seattle, WA - Spokane, WA</td>\n",
       "      <td>0.253372</td>\n",
       "      <td>0.0895097</td>\n",
       "      <td>-3.63982</td>\n",
       "      <td>-3.58877</td>\n",
       "      <td>2.6292</td>\n",
       "      <td>2.90342</td>\n",
       "      <td>7.97013</td>\n",
       "      <td>7.92617</td>\n",
       "      <td>3.89319</td>\n",
       "      <td>3.67828</td>\n",
       "      <td>-5.34093</td>\n",
       "      <td>-5.02276</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00551563</td>\n",
       "      <td>-0.0140232</td>\n",
       "      <td>0.0439603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Seattle, WA - St. Louis, MO</td>\n",
       "      <td>0.387131</td>\n",
       "      <td>0.127598</td>\n",
       "      <td>-22.2179</td>\n",
       "      <td>-2.30261</td>\n",
       "      <td>24.7768</td>\n",
       "      <td>29.561</td>\n",
       "      <td>82.4328</td>\n",
       "      <td>31.0897</td>\n",
       "      <td>22.6051</td>\n",
       "      <td>2.4302</td>\n",
       "      <td>-57.656</td>\n",
       "      <td>-1.5287</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622848</td>\n",
       "      <td>-0.896363</td>\n",
       "      <td>51.3431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Seattle, WA - Washington, DC</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.666804</td>\n",
       "      <td>-2.47563</td>\n",
       "      <td>-1.98754</td>\n",
       "      <td>13.0253</td>\n",
       "      <td>14.0076</td>\n",
       "      <td>34.8948</td>\n",
       "      <td>32.352</td>\n",
       "      <td>3.18753</td>\n",
       "      <td>2.65435</td>\n",
       "      <td>-21.8695</td>\n",
       "      <td>-18.3444</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0728704</td>\n",
       "      <td>-0.197156</td>\n",
       "      <td>2.5428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>St. Louis, MO - Tampa, FL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.51266e-08</td>\n",
       "      <td>5.90224e-08</td>\n",
       "      <td>0.00162509</td>\n",
       "      <td>0.00162508</td>\n",
       "      <td>2.17606e-08</td>\n",
       "      <td>2.17602e-08</td>\n",
       "      <td>-0.00162501</td>\n",
       "      <td>-0.00162502</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8.51856e-06</td>\n",
       "      <td>3.70814e-13</td>\n",
       "      <td>1.38435e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>St. Louis, MO - Washington, DC</td>\n",
       "      <td>0.365395</td>\n",
       "      <td>0.153563</td>\n",
       "      <td>-5.89367</td>\n",
       "      <td>-3.22371</td>\n",
       "      <td>10.4563</td>\n",
       "      <td>12.076</td>\n",
       "      <td>30.6791</td>\n",
       "      <td>24.014</td>\n",
       "      <td>6.25906</td>\n",
       "      <td>3.37727</td>\n",
       "      <td>-20.2229</td>\n",
       "      <td>-11.938</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217252</td>\n",
       "      <td>-0.453022</td>\n",
       "      <td>6.66511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              route initial_train_r2 final_train_r2  \\\n",
       "0          Albany, NY - Chicago, IL          0.76573       0.732433   \n",
       "1          Albany, NY - Orlando, FL         0.531803       0.416107   \n",
       "2     Albuquerque, NM - Chicago, IL         0.504485       0.415028   \n",
       "3      Albuquerque, NM - Dallas, TX                1              1   \n",
       "4     Albuquerque, NM - Houston, TX         0.999997       0.999996   \n",
       "..                              ...              ...            ...   \n",
       "398       Seattle, WA - Spokane, WA         0.253372      0.0895097   \n",
       "399     Seattle, WA - St. Louis, MO         0.387131       0.127598   \n",
       "400    Seattle, WA - Washington, DC         0.711897       0.666804   \n",
       "401       St. Louis, MO - Tampa, FL                1              1   \n",
       "402  St. Louis, MO - Washington, DC         0.365395       0.153563   \n",
       "\n",
       "    initial_test_r2 final_test_r2 initial_train_rmse final_train_rmse  \\\n",
       "0          -11.2114      -5.16686            21.0959          22.5453   \n",
       "1          -1.39964     -0.692976            9.25274          10.3329   \n",
       "2          -2.56934     -0.577167            8.39041          9.11637   \n",
       "3                 1             1        2.80657e-12       3.1308e-14   \n",
       "4          0.999874      0.999957          0.0176341        0.0208618   \n",
       "..              ...           ...                ...              ...   \n",
       "398        -3.63982      -3.58877             2.6292          2.90342   \n",
       "399        -22.2179      -2.30261            24.7768           29.561   \n",
       "400        -2.47563      -1.98754            13.0253          14.0076   \n",
       "401               1             1        8.51266e-08      5.90224e-08   \n",
       "402        -5.89367      -3.22371            10.4563           12.076   \n",
       "\n",
       "    initial_test_rmse final_test_rmse initial_r2_spread final_r2_spread  \\\n",
       "0             51.2771         36.4394           11.9772         5.89929   \n",
       "1             16.1668         13.5793           1.93145         1.10908   \n",
       "2              25.179         16.7372           3.07382        0.992195   \n",
       "3         3.50712e-12     7.12907e-14                 0               0   \n",
       "4           0.0499627       0.0291183       0.000123546     3.92844e-05   \n",
       "..                ...             ...               ...             ...   \n",
       "398           7.97013         7.92617           3.89319         3.67828   \n",
       "399           82.4328         31.0897           22.6051          2.4302   \n",
       "400           34.8948          32.352           3.18753         2.65435   \n",
       "401        0.00162509      0.00162508       2.17606e-08     2.17602e-08   \n",
       "402           30.6791          24.014           6.25906         3.37727   \n",
       "\n",
       "    initial_rmse_spread final_rmse_spread  test_rmse_improved  \\\n",
       "0              -30.1812          -13.8941                True   \n",
       "1              -6.91405          -3.24635                True   \n",
       "2              -16.7886          -7.62087                True   \n",
       "3          -7.00548e-13      -3.99828e-14                True   \n",
       "4            -0.0323287       -0.00825647                True   \n",
       "..                  ...               ...                 ...   \n",
       "398            -5.34093          -5.02276                True   \n",
       "399             -57.656           -1.5287                True   \n",
       "400            -21.8695          -18.3444                True   \n",
       "401         -0.00162501       -0.00162502                True   \n",
       "402            -20.2229           -11.938                True   \n",
       "\n",
       "     test_r2_improved test_rmse_improvement_% test_r2_improvement_%  \\\n",
       "0                True                0.289362             -0.539144   \n",
       "1                True                0.160052             -0.504891   \n",
       "2                True                0.335271             -0.775364   \n",
       "3                True                0.979673                     0   \n",
       "4                True                  0.4172           8.32619e-05   \n",
       "..                ...                     ...                   ...   \n",
       "398              True              0.00551563            -0.0140232   \n",
       "399              True                0.622848             -0.896363   \n",
       "400              True               0.0728704             -0.197156   \n",
       "401              True             8.51856e-06           3.70814e-13   \n",
       "402              True                0.217252             -0.453022   \n",
       "\n",
       "    test_rmse_improvement_amount  \n",
       "0                        14.8376  \n",
       "1                        2.58754  \n",
       "2                        8.44179  \n",
       "3                    3.43582e-12  \n",
       "4                      0.0208444  \n",
       "..                           ...  \n",
       "398                    0.0439603  \n",
       "399                      51.3431  \n",
       "400                       2.5428  \n",
       "401                  1.38435e-08  \n",
       "402                      6.66511  \n",
       "\n",
       "[321 rows x 18 columns]"
      ]
     },
     "execution_count": 1564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we are please to see although the models still need work we improved our RMSE score on 299 test models \n",
    "only_df[(only_df['initial_test_rmse'] >= 0) & (only_df['initial_train_rmse'] >= 0) & (only_df['test_rmse_improved'] == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model\n",
    "- Taking a quick peak at our ARIMA Model\n",
    "- Although this was heavily explored, ultimately I chose to focus on OLS.  The way we transformed features in OLS was a more sophisticated version of what is done in this model\n",
    "- Reason being the AIC scores were similar and it was a more interesting experienced to dive into OLS statsmodel and tune each route manually via ML.\n",
    "- With ARIMA not being able to calculate RMSE or R2 (make it a black box model) was something that shied us aways from it.\n",
    "- We took a look at our route 'Dallas, TX - Houston, TX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dal_hou_features\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_modeler(target_variable='airfare', itinerary='Dallas, TX - Houston, TX', exog_var=None, d=1, p=5, q=5, best_aic=1000, best_p=0, best_q=0):\n",
    "    \n",
    "    # dataframes and features\n",
    "    df_train = all_route_dict[itinerary]['train_dataframe'].copy()\n",
    "    df_unseen = all_route_dict[itinerary]['test_dataframe'].copy()\n",
    "    df_features = list(all_route_dict[itinerary]['train_dataframe'].columns)\n",
    "    \n",
    "    # train / test\n",
    "    train, test = train_test_split(df_train['airfare'], test_size = 0.1, shuffle = False)\n",
    "\n",
    "    for p in range(p):                                                    # Grid Test the ARIMA Model\n",
    "        for q in range(q):\n",
    "            try:\n",
    "                model = ARIMA(endog = train.astype(float).dropna(), # Instantiate & Fit ARIMA model\n",
    "                              order = (p, d, q), # exog = df_train[exog_var][train.index], \n",
    "                              freq = 'M').fit() \n",
    "                if model.aic < best_aic:                                  # Is current model AIC better than best_aic variable?\n",
    "                    best_aic = model.aic                                  # If so, then overwrite\n",
    "                    best_p = p                                            # If so, then overwrite\n",
    "                    best_q = q                                            # If so, then overwrite\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    new_model = ARIMA(endog = train.astype(float).dropna(),\n",
    "                              order = (best_p, d, best_q),\n",
    "                              freq = 'M').fit()\n",
    "    \n",
    "    print()\n",
    "    print(f'Complete! Minimize AIC on train data with ARIMA({best_p}, {d}, {best_q}).')\n",
    "    print()    \n",
    "    print(f'Best AIC: {best_aic}.')\n",
    "    print()\n",
    "    \n",
    "    return model, new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylucci/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py:472: FutureWarning: \n",
      "statsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\n",
      "been deprecated in favor of statsmodels.tsa.arima.model.ARIMA (note the .\n",
      "between arima and model) and\n",
      "statsmodels.tsa.SARIMAX. These will be removed after the 0.12 release.\n",
      "\n",
      "statsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\n",
      "is both well tested and maintained.\n",
      "\n",
      "To silence this warning and continue using ARMA and ARIMA until they are\n",
      "removed, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
      "                        FutureWarning)\n",
      "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
      "                        FutureWarning)\n",
      "\n",
      "  warnings.warn(ARIMA_DEPRECATION_WARN, FutureWarning)\n",
      "/Users/tonylucci/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete! Minimize AIC on train data with ARIMA(2, 1, 2).\n",
      "\n",
      "Best AIC: 363.7379387273425.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonylucci/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>ARIMA Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>D.airfare</td>    <th>  No. Observations:  </th>    <td>105</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>          <td>ARIMA(4, 1, 0)</td>  <th>  Log Likelihood     </th> <td>-180.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>css-mle</td>     <th>  S.D. of innovations</th>   <td>1.354</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 12 Oct 2020</td> <th>  AIC                </th>  <td>373.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:30:56</td>     <th>  BIC                </th>  <td>389.529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>           <td>04-30-1997</td>    <th>  HQIC               </th>  <td>380.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                 <td>- 12-31-2005</td>   <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>    0.1818</td> <td>    0.114</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.043</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1.D.airfare</th> <td>   -0.0199</td> <td>    0.097</td> <td>   -0.205</td> <td> 0.838</td> <td>   -0.211</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L2.D.airfare</th> <td>   -0.0192</td> <td>    0.097</td> <td>   -0.198</td> <td> 0.843</td> <td>   -0.209</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L3.D.airfare</th> <td>   -0.0886</td> <td>    0.098</td> <td>   -0.907</td> <td> 0.364</td> <td>   -0.280</td> <td>    0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L4.D.airfare</th> <td>   -0.0316</td> <td>    0.111</td> <td>   -0.283</td> <td> 0.777</td> <td>   -0.250</td> <td>    0.187</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Roots</caption>\n",
       "<tr>\n",
       "    <td></td>   <th>            Real</th>  <th>         Imaginary</th> <th>         Modulus</th>  <th>        Frequency</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.1</th> <td>           1.1333</td> <td>          -1.5935j</td> <td>           1.9554</td> <td>          -0.1516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.2</th> <td>           1.1333</td> <td>          +1.5935j</td> <td>           1.9554</td> <td>           0.1516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.3</th> <td>          -2.5359</td> <td>          -1.3592j</td> <td>           2.8772</td> <td>          -0.4217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.4</th> <td>          -2.5359</td> <td>          +1.3592j</td> <td>           2.8772</td> <td>           0.4217</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             ARIMA Model Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:              D.airfare   No. Observations:                  105\n",
       "Model:                 ARIMA(4, 1, 0)   Log Likelihood                -180.803\n",
       "Method:                       css-mle   S.D. of innovations              1.354\n",
       "Date:                Mon, 12 Oct 2020   AIC                            373.606\n",
       "Time:                        20:30:56   BIC                            389.529\n",
       "Sample:                    04-30-1997   HQIC                           380.058\n",
       "                         - 12-31-2005                                         \n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const               0.1818      0.114      1.588      0.112      -0.043       0.406\n",
       "ar.L1.D.airfare    -0.0199      0.097     -0.205      0.838      -0.211       0.171\n",
       "ar.L2.D.airfare    -0.0192      0.097     -0.198      0.843      -0.209       0.170\n",
       "ar.L3.D.airfare    -0.0886      0.098     -0.907      0.364      -0.280       0.103\n",
       "ar.L4.D.airfare    -0.0316      0.111     -0.283      0.777      -0.250       0.187\n",
       "                                    Roots                                    \n",
       "=============================================================================\n",
       "                  Real          Imaginary           Modulus         Frequency\n",
       "-----------------------------------------------------------------------------\n",
       "AR.1            1.1333           -1.5935j            1.9554           -0.1516\n",
       "AR.2            1.1333           +1.5935j            1.9554            0.1516\n",
       "AR.3           -2.5359           -1.3592j            2.8772           -0.4217\n",
       "AR.4           -2.5359           +1.3592j            2.8772            0.4217\n",
       "-----------------------------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 1567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First the first model results!\n",
    "dal_tex, dal_tex_new = arima_modeler()\n",
    "dal_tex.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>ARIMA Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>D.airfare</td>    <th>  No. Observations:  </th>    <td>105</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>          <td>ARIMA(2, 1, 2)</td>  <th>  Log Likelihood     </th> <td>-175.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>css-mle</td>     <th>  S.D. of innovations</th>   <td>1.245</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 12 Oct 2020</td> <th>  AIC                </th>  <td>363.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:30:56</td>     <th>  BIC                </th>  <td>379.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>           <td>04-30-1997</td>    <th>  HQIC               </th>  <td>370.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                 <td>- 12-31-2005</td>   <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>    0.1906</td> <td>    0.009</td> <td>   21.672</td> <td> 0.000</td> <td>    0.173</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L1.D.airfare</th> <td>    1.8001</td> <td>    0.063</td> <td>   28.655</td> <td> 0.000</td> <td>    1.677</td> <td>    1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ar.L2.D.airfare</th> <td>   -0.8262</td> <td>    0.059</td> <td>  -13.954</td> <td> 0.000</td> <td>   -0.942</td> <td>   -0.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L1.D.airfare</th> <td>   -1.9983</td> <td>    0.061</td> <td>  -32.599</td> <td> 0.000</td> <td>   -2.118</td> <td>   -1.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ma.L2.D.airfare</th> <td>    0.9983</td> <td>    0.061</td> <td>   16.270</td> <td> 0.000</td> <td>    0.878</td> <td>    1.119</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Roots</caption>\n",
       "<tr>\n",
       "    <td></td>   <th>            Real</th>  <th>         Imaginary</th> <th>         Modulus</th>  <th>        Frequency</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.1</th> <td>           1.0894</td> <td>          -0.1535j</td> <td>           1.1002</td> <td>          -0.0223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.2</th> <td>           1.0894</td> <td>          +0.1535j</td> <td>           1.1002</td> <td>           0.0223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MA.1</th> <td>           1.0000</td> <td>          +0.0000j</td> <td>           1.0000</td> <td>           0.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MA.2</th> <td>           1.0017</td> <td>          +0.0000j</td> <td>           1.0017</td> <td>           0.0000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             ARIMA Model Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:              D.airfare   No. Observations:                  105\n",
       "Model:                 ARIMA(2, 1, 2)   Log Likelihood                -175.869\n",
       "Method:                       css-mle   S.D. of innovations              1.245\n",
       "Date:                Mon, 12 Oct 2020   AIC                            363.738\n",
       "Time:                        20:30:56   BIC                            379.662\n",
       "Sample:                    04-30-1997   HQIC                           370.191\n",
       "                         - 12-31-2005                                         \n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const               0.1906      0.009     21.672      0.000       0.173       0.208\n",
       "ar.L1.D.airfare     1.8001      0.063     28.655      0.000       1.677       1.923\n",
       "ar.L2.D.airfare    -0.8262      0.059    -13.954      0.000      -0.942      -0.710\n",
       "ma.L1.D.airfare    -1.9983      0.061    -32.599      0.000      -2.118      -1.878\n",
       "ma.L2.D.airfare     0.9983      0.061     16.270      0.000       0.878       1.119\n",
       "                                    Roots                                    \n",
       "=============================================================================\n",
       "                  Real          Imaginary           Modulus         Frequency\n",
       "-----------------------------------------------------------------------------\n",
       "AR.1            1.0894           -0.1535j            1.1002           -0.0223\n",
       "AR.2            1.0894           +0.1535j            1.1002            0.0223\n",
       "MA.1            1.0000           +0.0000j            1.0000            0.0000\n",
       "MA.2            1.0017           +0.0000j            1.0017            0.0000\n",
       "-----------------------------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 1568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the best model results\n",
    "dal_tex_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>airfare</td>     <th>  R-squared:         </th> <td>   0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>2.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:30:56</td>     <th>  Log-Likelihood:    </th> <td> -237.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    82</td>      <th>  AIC:               </th> <td>   489.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    75</td>      <th>  BIC:               </th> <td>   505.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                       <td>   -0.0030</td> <td>    0.001</td> <td>   -4.711</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_cost_per_mile_diff_1</th>     <td>  911.6358</td> <td>  347.708</td> <td>    2.622</td> <td> 0.011</td> <td>  218.966</td> <td> 1604.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_flight_revenue_diff_2</th>    <td> 4.358e-06</td> <td> 2.08e-06</td> <td>    2.099</td> <td> 0.039</td> <td> 2.22e-07</td> <td> 8.49e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_airfare_diff_1</th>           <td>   -4.0965</td> <td>    1.787</td> <td>   -2.293</td> <td> 0.025</td> <td>   -7.656</td> <td>   -0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_time_diff_1</th>              <td>   -1.2160</td> <td>    0.258</td> <td>   -4.711</td> <td> 0.000</td> <td>   -1.730</td> <td>   -0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_passengers_diff_2</th>        <td>   -0.0004</td> <td>    0.000</td> <td>   -2.159</td> <td> 0.034</td> <td>   -0.001</td> <td>-2.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sf_total_flight_cost_diff_2</th> <td> 2.335e-05</td> <td> 1.04e-05</td> <td>    2.255</td> <td> 0.027</td> <td> 2.73e-06</td> <td>  4.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dist_miles</th>                  <td>    2.5084</td> <td>    0.454</td> <td>    5.523</td> <td> 0.000</td> <td>    1.604</td> <td>    3.413</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.809</td> <th>  Durbin-Watson:     </th> <td>   0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.246</td> <th>  Jarque-Bera (JB):  </th> <td>   2.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.419</td> <th>  Prob(JB):          </th> <td>   0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.050</td> <th>  Cond. No.          </th> <td>9.55e+21</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.9e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                airfare   R-squared:                       0.336\n",
       "Model:                            OLS   Adj. R-squared:                  0.282\n",
       "Method:                 Least Squares   F-statistic:                     6.314\n",
       "Date:                Mon, 12 Oct 2020   Prob (F-statistic):           2.08e-05\n",
       "Time:                        20:30:56   Log-Likelihood:                -237.49\n",
       "No. Observations:                  82   AIC:                             489.0\n",
       "Df Residuals:                      75   BIC:                             505.8\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "const                          -0.0030      0.001     -4.711      0.000      -0.004      -0.002\n",
       "sf_cost_per_mile_diff_1       911.6358    347.708      2.622      0.011     218.966    1604.306\n",
       "sf_flight_revenue_diff_2     4.358e-06   2.08e-06      2.099      0.039    2.22e-07    8.49e-06\n",
       "sf_airfare_diff_1              -4.0965      1.787     -2.293      0.025      -7.656      -0.537\n",
       "sf_time_diff_1                 -1.2160      0.258     -4.711      0.000      -1.730      -0.702\n",
       "sf_passengers_diff_2           -0.0004      0.000     -2.159      0.034      -0.001   -2.92e-05\n",
       "sf_total_flight_cost_diff_2  2.335e-05   1.04e-05      2.255      0.027    2.73e-06     4.4e-05\n",
       "dist_miles                      2.5084      0.454      5.523      0.000       1.604       3.413\n",
       "==============================================================================\n",
       "Omnibus:                        2.809   Durbin-Watson:                   0.181\n",
       "Prob(Omnibus):                  0.246   Jarque-Bera (JB):                2.408\n",
       "Skew:                           0.419   Prob(JB):                        0.300\n",
       "Kurtosis:                       3.050   Cond. No.                     9.55e+21\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.9e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now our OLS results for the same route\n",
    "all_route_dict['Dallas, TX - Houston, TX']['final_model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION / BUSINESS RECOMMENDATIONS\n",
    "## WINS\n",
    "- We succeeded in building 63 separate route specific that predicted R2 scores between 90-100% out of 375 total routes examined.\n",
    "\n",
    "- From this we can be confident to tell an individual that when they are searching for a flight, they should cross reference their findings with our prediction model.  Of course it will be up to them, but they will be empowered to make a decision whether to buy this flight now, or wait until a future date dependent on their own personal budget.\n",
    "\n",
    "- We succeed in improving RMSE scores 21.85% on 299 of our 375 total routes.  From starting with an initial featureset and using machine learning to make feature selection based on specific conditions.\n",
    "\n",
    "- 265 out of 375 of our test R2 scores outperformed the baseline scores\n",
    "\n",
    "## FUTURE THOUGHTS\n",
    "\n",
    "- As we knew predicting airling pricing is a very tricky task.  Ensuring we get as much granular information as possible can be a next step to further building out this project and finding patterns to build more effective models.\n",
    "\n",
    "- Given more time I would look to scrape the web for pricing information for flights perhaps down to the daily / Hourly level.  So much goes into airpline pricing and as we all know the time of the purchase really makes a difference.\n",
    "\n",
    "- We'd love to build a web app where individuals can plug their price quote into it that will let them know how much savings they will make by booking the flight now, and, perhaps, show them where we seee the price going over the next 3 months so they create urgency in themselves for making the purchase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
